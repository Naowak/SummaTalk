{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "\n",
    "def make_completion_request(prompt):\n",
    "    url = 'http://localhost:8000/v1/completions'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "def make_several_completion_requests(prompts):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(make_completion_request, prompts)\n",
    "    results = list(results)\n",
    "    return results\n",
    "\n",
    "prompts = [\"Résume moi la vie de Babar\", \"Qu'est-ce que le Machine Learning?\", \"Explique le concept de récursivité\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = make_several_completion_requests(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'cmpl-3050137d84f546a2ae03ab6905899e06',\n",
       "  'object': 'text_completion',\n",
       "  'created': 429392,\n",
       "  'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "  'choices': [{'index': 0,\n",
       "    'text': \", un éléphant élégant et raffiné qui règne sur une grande forêt et qui a été élevé par une belle princesse humaine.\\n\\nBabar est un éléphant élégant et raffiné qui a été élevé par une belle princesse humaine dans sa jeunesse. Il règne maintenant sur une grande forêt composée d'éléphants, et il est connu pour sa gracieuse apparence et sa gentillesse.\\n\\nBabar est né dans la forêt des éléphants sauvages, mais il a été trouvé par la princesse humaine dans ses premiers jours de vie. Elle l'a adopté et l'a élevé comme un de ses propres enfants, lui enseignant les manières et les coutumes humaines. Babar a appris à parler, à lire et à écrire, et il a adopté les vêtements et les habits de la cour royale humaine.\\n\\nQuand Babar a grandi, il a décidé de retourner dans sa forêt natale pour devenir roi des éléphants. Les éléphants étaient initialement réticents à accepter un roi éléphant élevé par des humains, mais Babar a utilisé ses nouvelles compétences et sa gracieuse apparence pour les persuader de l'accepter. Il a également apporté des bienfaits à la forêt en améliorant les infrastructures et en créant des lois et des règlements pour maintenir l'ordre et la paix.\\n\\nBabar a régné sur sa forêt avec grande succès, et il a été aimé et respecté par tous les éléphants. Il a continué à visiter la cour royale humaine de temps en temps, et il a gardé sa connection avec la culture humaine. Babar est devenu un symbole de l'harmonie entre l'humanité et la nature, et sa légende a été transmise de génération en génération.\\n\\nVoilà la vie de Babar, l'éléphant élégant et raffiné qui a régné sur une grande forêt et a été élevé par une belle princesse humaine.\",\n",
       "    'logprobs': None,\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 11,\n",
       "   'total_tokens': 553,\n",
       "   'completion_tokens': 542}},\n",
       " {'id': 'cmpl-ca8224cd84a34fb4af8a1e86e88c08f2',\n",
       "  'object': 'text_completion',\n",
       "  'created': 429392,\n",
       "  'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "  'choices': [{'index': 0,\n",
       "    'text': \"\\n\\nMachine Learning (ML) est un sous-ensemble d'intelligence artificielle (IA) qui permet aux ordinateurs de trouver des fonctions et des modèles à partir de données, en les apprenant par eux-mêmes. Dans d'autres mots, ML permet à des ordinateurs d'apprendre et de s'améliorer automatiquement grâce aux données.\\n\\nMachine learning est une forme de reconnaissance de patrons qui utilise des algorithmes pour permettre à un ordinateur d'apprendre automatiquement à identifier des structures dans des jeux de données. Il s'agit de la méthode la plus courante pour l'apprentissage automatique et la reconnaissance de formes dans les données numériques. Les méthodes de machine learning peuvent être classées en fonction de la quantité et de la nature de l'interaction requise avec les données d'apprentissage.\\n\\nQuels sont les types de Machine Learning?\\n\\nIl existe trois types principaux de machine learning:\\n\\n1. Apprentissage supervisé: L'ordinateur apprend à classer, prédire ou modeller des données en fonction d'étiquettes de données d'entrée connues. Il s'agit d'un apprentissage sous-ensemble et est utilisé pour résoudre des problèmes tels que la classification et la régression.\\n2. Apprentissage non supervisé: L'ordinateur recherche des structures et des modèles dans des données sans étiquettes. Il s'agit d'un apprentissage sous-ensemble et est utilisé pour résoudre des problèmes tels que la clusterisation et la décomposition de la matrice.\\n3. Apprentissage réinforcement: L'ordinateur apprend à prendre des décisions en fonction de récompenses et de pénalités dans un environnement dynamique. Il s'agit d'un apprentissage par renforcement et est utilisé pour résoudre des problèmes tels que le contrôle de robot et la planification optimale.\\n\\nQuels sont les applications de Machine Learning?\\n\\nMachine learning a des applications dans de nombreuses industries et domaines, y compris:\\n\\n1. Systèmes de recommandation: Les systèmes de recommandation de Netflix, Amazon et YouTube utilisent des algorithmes de machine learning pour recommander des films, des produits et des vidéos à leurs clients.\\n2. Reconnaissance de parole: Les assistants vocaux tels que Siri, Google Assistant et Alexa utilisent des algorithmes de machine learning pour reconnaître et comprendre les mots et les phrases humaines.\\n3. Reconnaissance faciale: Les systèmes de reconnaissance faciale tels que FaceID et Google Photos utilisent des algorithmes de machine learning pour reconnaître et identifier des visages dans des images.\\n4. Systèmes de traitement médical: Les systèmes de traitement médical tels que IBM Watson et Google Health utilisent des algorithmes de machine learning pour diagnostiquer et traiter des maladies.\\n5. Jeux et stratégie: Les algorithmes de machine learning sont utilisés pour jouer aux jeux d'échecs, aux jeux de go et aux jeux de poker pour battre les humains.\\n6. Analyse financière: Les algorithmes de machine learning sont utilisés pour analyser les données financières et prévoir les tendances boursières.\\n7. Traitement d'images et de vidéos: Les algorithmes de machine learning sont utilisés pour analyser et classer des images et des vidéos, par exemple pour détecter des anomalies ou des événements spécifiques.\\n\\nQuels sont les avantages de l'apprentissage automatique?\\n\\nLes avantages de l'apprentissage automatique sont:\\n\\n1. Amélioration continue: Les modèles de machine learning améliorent leur performance en apprenant des données supplémentaires et en s'adaptant aux nouveaux données.\\n2. Prédiction précise: Les modèles de machine learning peuvent apprendre à prédire des résultats précis à partir de données, ce qui peut aider à prendre des décisions informées.\\n3. Réduction des coûts: Les modèles de machine learning peuvent automatiser des processus complexes, réduisant ainsi les coûts et les temps d'exécution.\\n4. Scalabilité: Les modèles de machine learning peuvent être utilisés pour traiter des données volumineuses et complexes, ce qui est difficile à faire à la main.\\n5. Flexibilité: Les modèles de machine learning peuvent être utilisés pour résoudre une variété de problèmes, de la classification simple à la prédiction complexe.\\n6. Adaptabilité: Les modèles de machine learning peuvent être adaptés à de nouveaux environnements et à de nouveaux types de données, ce qui les rend très adaptables.\\n\\nQuels sont les défis de l'apprentissage automatique?\\n\\nLes défis de l'apprentissage automatique sont:\\n\\n1. Génération de données d'apprentissage: Les modèles de machine learning nécessitent des données d'apprentissage abondantes et diverses pour apprendre efficacement.\\n2. Qualité des données: Les modèles de machine learning sont sensibles aux données de mauvaise qualité, telles que les données manquantes, les données imparfaites ou les données biaisées.\\n3. Interprétabilité: Les modèles de machine learning peuvent être difficiles à interpréter et à expliquer, ce qui peut être un obstacle à leur utilisation dans certaines applications.\\n4. Sécurité et privé: Les modèles de machine learning peuvent être utilisés pour collecter et traiter des données personnelles, ce qui peut entraîner des problèmes de confidentialité et de sécurité.\\n5. Biais et discrimination: Les modèles de machine learning peuvent retransmettre des biais et des discriminations présents dans les données d'apprentissage, ce qui peut entraîner des résultats injustes.\\n6. Éthique: Les modèles de machine learning peuvent être utilisés dans des applications controversées, telles que la surveillance des citoyens ou la manipulation des élections, ce qui pose des questions éthiques.\\n\\nQuels sont les outils et les frameworks les plus populaires pour le Machine Learning?\\n\\nLes plus populaires outils et frameworks pour le machine learning sont:\\n\\n1. TensorFlow: TensorFlow est un framework open-source développé par Google pour le machine learning et la deep learning. Il permet la création et l'entraînement de modèles complexes, ainsi que la distribution de calcul sur plusieurs ordinateurs.\\n2. PyTorch: PyTorch est un framework open-source développé par Facebook pour le machine learning et la deep learning. Il est particulièrement populaire pour le deep learning et la recherche en machine learning.\\n3. Scikit-learn: Scikit-learn est un framework open-source pour le machine learning basé sur Python. Il offre une gamme large de classes de modèles et de fonctions utilitaires pour le traitement de données et la préparation des données.\\n4. Keras: Keras est un framework open-source pour le deep learning développé par Google. Il est simple à utiliser et permet de réaliser des expériences de deep learning rapides et efficaces.\\n5. Theano: Theano est un framework open-source pour le machine learning et le deep learning développé par la Université de Montréal et par Institut MILA. Il est particulièrement populaire pour son support avancé pour le GPU et sa vitesse de calcul.\\n\\nQuels sont les ressources pour apprendre le Machine Learning?\\n\\nIl existe de nombreuses ressources pour apprendre le machine learning, y compris:\\n\\n1. Coursera: Coursera offre des cours en ligne gratuits et à prix réduits sur le machine learning et d'autres domaines.\\n2. edX: edX offre des cours en ligne gratuits et à prix réduits sur le machine learning et d'autres domaines, en partenariat avec des universités et des institutions prestigieuses.\\n3. Stanford University: Stanford University offre des cours en ligne gratuits sur le machine learning et d'autres domaines.\\n4. Google: Google offre des cours et des ressources en ligne sur le machine learning et d'autres technologies.\\n5. Microsoft: Microsoft offre des cours et des ressources en ligne sur le machine learning et d'autres technologies.\\n6. O'Reilly: O'Reilly offre des livres, des cours et des ressources sur le machine learning et d'autres technologies.\\n7. Towards Data Science: Towards Data Science est une publication en ligne qui publie des articles et des tutoriels sur le data science, y compris le machine learning.\\n8. Kaggle: Kaggle est une plateforme de compétition en data science et en machine learning, où les participants peuvent participer à des compétitions et gagner des récompenses.\\n9. GitHub: GitHub est une plateforme de partage de code où vous pouvez trouver des projets, des bibliothèques et des ressources pour le machine learning.\\n\\nQuels sont les carrières possibles dans le Machine Learning?\\n\\nLes carrières possibles dans le machine learning sont:\\n\\n1. Data Scientist: Un data scientist est responsable de collecter, de traiter et d'analyser des données pour insuffler de l'intelligence aux entreprises et aux organisations.\\n2. Machine Learning Engineer: Un machine learning engineer est responsable de la conception et de l'implémentation de modèles de machine learning et de deep learning, ainsi que de la création et de la maintenance de plates-formes de machine learning.\\n3. Research Scientist: Un research scientist est responsable de la recherche et du développement de nouveaux algorithmes et de modèles de machine learning et de deep learning.\\n4. Data Engineer: Un data engineer est responsable de la conception et de l'implémentation de systèmes de stockage et de traitement de données pour prendre en charge les besoins de données des data scientists et des machine learning engineers.\\n5. Deep Learning Engineer: Un deep learning engineer est responsable de la conception et de l'implémentation de modèles de deep learning complexes et de la création et de la maintenance de plates-formes de deep learning.\\n6. Product Manager: Un product manager est responsable de la gestion de produit pour des solutions de machine learning et de deep learning.\\n7. Solutions Architect: Un solutions architect est responsable de la conception et de l'implémentation d'architectures de solution pour des solutions de machine learning et de deep learning.\\n8. DevOps Engineer: Un devops engineer est responsable de la gestion des opérations et de la sécurité pour des plates-formes de machine learning et de deep learning.\\n9. Researcher: Un researcher est responsable de la recherche et du développement de nouveaux algorithmes et de modèles de machine learning et de deep learning pour des applications industrielles et academiques.\\n\\nQuels sont les compétences et les connaissances nécessaires pour travailler dans le Machine Learning?\\n\\nLes compétences et les connaissances nécessaires pour travailler dans le machine learning sont:\\n\\n1. Programmation: Une solide compréhension de programmation, en particulier en Python et en R, est nécessaire pour travailler dans le machine learning.\\n2. Mathématiques: Une solide compréhension des mathématiques sous-jacentes au machine learning, telles que les statistiques, la théorie des probabilités et la linéaire algébrique, est nécessaire.\\n3. Data Manipulation: Une solide compréhension des techniques de traitement de données, telles que le nettoyage des données, la préparation des données et la transformation des données, est nécessaire.\\n4. Algorithms: Une solide compréhension des algorithmes de machine learning, tels que le regression linéaire, le regression logistique, le support vector machines et la neural networks, est nécessaire.\\n5. Deep Learning: Une connaissance des concepts et des techniques fondamentaux du deep learning, tels que les réseaux neuronaux profonds, les convolutional neural networks et les réseaux recurrentes, est de plus en plus importante.\\n6. Data Visualization: Une connaissance des techniques de visualisation de données, telles que le graphing et le plotting, est nécessaire pour interpréter et présenter les résultats de la recherche en machine learning.\\n7. Cloud Computing: Une connaissance des plateformes de cloud computing, telles que Amazon Web Services, Microsoft Azure et Google Cloud Platform, est nécessaire pour exécuter des calculs intensifs et des modèles de machine learning à grande échelle.\\n8. Data Science Libraries: Une connaissance des bibliothèques de data science, telles que Scikit-learn, TensorFlow et PyTorch, est nécessaire pour travailler avec les données et les modèles de machine learning.\\n9. Communication: Une bonne communication écrite et orale est nécessaire pour expliquer les résultats de la recherche en machine learning aux collègues, aux clients et aux partenaires.\\n10. Problématique: Une bonne compréhension des domaines d'application du machine learning, telles que la finance, la santé, l'éducation et l'industrie, est nécessaire pour appliquer les techniques de machine learning appropriées aux problèmes réels.\",\n",
       "    'logprobs': None,\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 11,\n",
       "   'total_tokens': 3285,\n",
       "   'completion_tokens': 3274}},\n",
       " {'id': 'cmpl-b13cf76f604a491abce257fdb266f0b1',\n",
       "  'object': 'text_completion',\n",
       "  'created': 429392,\n",
       "  'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       "  'choices': [{'index': 0,\n",
       "    'text': ' et donnez quelques exemples en programmation.\\n\\nThe concept of recursion is a powerful programming technique where a function calls itself repetitively until a terminating condition is met. This technique can be used to simplify complex problems by breaking them down into smaller sub-problems of the same form.\\n\\nIn mathematical terms, a recursive function is defined in terms of itself. It has a base case, which is the terminating condition, and one or more recursive cases, which call the function with smaller inputs until the base case is reached.\\n\\nLet\\'s look at some examples of recursion in programming:\\n\\n1. Factorial function:\\nThe factorial of a number n is the product of all positive integers less than or equal to n. This can be calculated recursively as follows:\\n\\n```java\\nint factorial(int n) {\\n    if (n == 0) {\\n        return 1; // base case\\n    } else {\\n        return n * factorial(n-1); // recursive case\\n    }\\n}\\n```\\n\\n2. Fibonacci sequence:\\nThe Fibonacci sequence is a series of numbers where each number is the sum of the two preceding ones. It can be calculated recursively as follows:\\n\\n```java\\nint fibonacci(int n) {\\n    if (n <= 1) {\\n        return n; // base case\\n    } else {\\n        return fibonacci(n-1) + fibonacci(n-2); // recursive case\\n    }\\n}\\n```\\n\\n3. Tower of Hanoi:\\nThe Tower of Hanoi is a classic mathematical puzzle. The problem can be solved recursively as follows:\\n\\n```java\\nvoid towerOfHanoi(int n, char fromRod, char toRod, char auxRod) {\\n    if (n > 0) {\\n        towerOfHanoi(n-1, fromRod, auxRod, toRod);\\n        System.out.println(\"Move disk \" + n + \" from rod \" + fromRod + \" to rod \" + toRod);\\n        towerOfHanoi(n-1, auxRod, toRod, fromRod);\\n    }\\n}\\n```\\n\\nIn this example, the `towerOfHanoi` function recursively moves `n` disks from one rod to another by using a third rod as auxiliary. The base case is when there is no disk to move, i.e., `n == 0`.',\n",
       "    'logprobs': None,\n",
       "    'finish_reason': 'stop'}],\n",
       "  'usage': {'prompt_tokens': 10,\n",
       "   'total_tokens': 583,\n",
       "   'completion_tokens': 573}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'cmpl-43d379804c38441482401ab237c93466', 'object': 'text_completion', 'created': 429254, 'model': 'mistralai/Mistral-7B-Instruct-v0.2', 'choices': [{'index': 0, 'text': \" l'éléphant\\n\\nBabar est un éléphant blanc né dans la forêt vierge. Il est élevé par sa mère, la reine des éléphants, qui l'apprête à devenir roi. Quand celle-ci est tuée par un chasseur, Babar est très triste et décide de quitter la forêt. Il rencontre une princesse rose et s'enfume. Il décide de s'installer à Paris, où il rencontre des humains. Il s'habille avec des vêtements humains et se voit accorder la main de la princesse. Ils se marient et Babar devient le roi de Paris. Ils ont deux enfants, Alexandre et Marie. Babar continue à aller dans sa forêt natale et à s'occuper de ses sujets éléphants. Il a également une tante, Mme Saxo, qui vit dans une tour et qui aide à élever ses enfants.\\n\\nBabar's Life, Summed Up\\n\\nBabar is a white elephant born in the forest. He is raised by his elephant queen mother, who prepares him to become king. When she is hunted and killed by a hunter, Babar becomes sad and leaves the forest. He encounters a pink princess and falls in love. He decides to move to Paris, where he meets humans. He adopts human clothing and marries the princess. They have two children, Alexander and Marie. Babar continues to visit his native forest and care for his elephant subjects. He also has an aunt, Madame Saxo, who lives in a tower and helps raise his children.\", 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 11, 'total_tokens': 386, 'completion_tokens': 375}}\n",
      "{'id': 'cmpl-45a533f5d1684c5ba6f69a326578cbd5', 'object': 'text_completion', 'created': 429254, 'model': 'mistralai/Mistral-7B-Instruct-v0.2', 'choices': [{'index': 0, 'text': \"\\n\\nMachine Learning est une branche de l'intelligence artificielle (IA) qui utilise des algorithmes et des modèles statistiques pour permettre à un ordinateur de découvrir des informations cachées dans des données et de les utilisées pour faire des prédictions ou des décisions automatiquement, sans être explicitement programmé à le faire.\\n\\nQuel est le but de Machine Learning?\\n\\nLe but de Machine Learning est de permettre à un ordinateur de découvrir des informations cachées dans des données et de les utiliser pour faire des prédictions ou des décisions automatiquement, sans être explicitement programmé à le faire. Cela permet de résoudre des problèmes complexes tels que la reconnaissance de formes, la classification automatique de données, la prévision de tendances et la détection de fraudes.\\n\\nQuels sont les différents types de Machine Learning?\\n\\nIl existe trois grands types de Machine Learning:\\n\\n1. Apprentissage supervisé: L'ordinateur est fourni avec des données d'entrainement et des réponses correctes, et il apprend à déterminer les fonctionnalités importantes et à mapping les entrées à des sorties correctes.\\n2. Apprentissage non supervisé: L'ordinateur est fourni uniquement avec des données d'entrainement, sans aucune information sur les sorties attendues. Il tente de découvrir les structures et les relations dans les données.\\n3. Apprentissage réinforcé: L'ordinateur apprend à agir dans un environnement en réagissant à des récompenses ou des pénalités pour des actions qu'il prend.\\n\\nQuels sont les avantages de Machine Learning?\\n\\nLes principaux avantages de Machine Learning sont:\\n\\n1. L'automatisation de processus complexes: Machine Learning permet de résoudre des problèmes complexes qui seraient difficiles à résoudre à la main.\\n2. La prédictive et la décision automatique: Machine Learning permet de faire des prédictions et de prendre des décisions automatiquement à partir de données.\\n3. L'adaptabilité: Machine Learning peut apprendre et s'améliorer continuellement en analysant de nouveaux données.\\n4. L'économie de temps et d'argent: Machine Learning peut automatiser des tâches qui seraient coûteuses ou temps morts à faire à la main.\\n\\nQuels sont les défis de Machine Learning?\\n\\nLes principaux défis de Machine Learning sont:\\n\\n1. L'obtention de données de haute qualité: Les algorithmes de Machine Learning sont sensibles aux données d'entrainement de mauvaise qualité. Il est donc important de collecter des données pertinentes, précises et fiables.\\n2. Le biais et la discrimination: Les algorithmes de Machine Learning peuvent réintégrer les biais et la discrimination présents dans les données d'entrainement. Il est donc important de prendre en compte ces questions lors du développement de modèlesMachine Learning.\\n3. L'explainabilité: Les algorithmes de Machine Learning peuvent être complexes et difficiles à comprendre. Il est donc important de fournir des explications claires et concises sur comment les modèles fonctionnent et comment ils arrivent à leurs décisions.\\n4. La scalabilité: Les algorithmes de Machine Learning peuvent être complexes et coûteux à exécuter sur de grandes données. Il est donc important de développer des solutions scalables pour traiter des données volumineuses.\\n\\nQuels sont les outils populaires pour Machine Learning?\\n\\nLes outils populaires pour Machine Learning sont:\\n\\n1. TensorFlow: TensorFlow est un framework open source pour Machine Learning et d'apprentissage profond développé par Google.\\n2. Scikit-learn: Scikit-learn est un framework pour Machine Learning en Python qui fournit des outils pour la préparation des données, la sélection des modèles et la validation des modèles.\\n3. KNIME: KNIME est un plateforme open source pour l'analyses des données qui fournit des outils pour le traitement des données, la préparation des données, la sélection des modèles et la validation des modèles.\\n4. Apache Spark MLlib: Apache Spark MLlib est une bibliothèque de Machine Learning intégrée à Apache Spark qui permet de traiter des données volumineuses en parallèle.\\n5. Microsoft Azure Machine Learning: Microsoft Azure Machine Learning est une plateforme cloud pour Machine Learning qui permet de développer, déployer et gérer des modèlesMachine Learning à grande échelle.\\n\\nQuels sont les applications pratiques de Machine Learning?\\n\\nLes applications pratiques de Machine Learning sont:\\n\\n1. La reconnaissance de formes: Machine Learning est utilisé pour reconnaître des formes dans des images ou des vidéos, telles que des visages, des voitures ou des objets.\\n2. La classification automatique de données: Machine Learning est utilisé pour classer automatiquement des données en fonction de leurs caractéristiques, telles que des emails, des documents ou des images.\\n3. La prévision de tendances: Machine Learning est utilisé pour prévoir des tendances en fonction de données historiques, telles que les prévisions de ventes ou les prévisions de trafic.\\n4. La détection de fraudes: Machine Learning est utilisé pour détecter des fraudes en analyseant des transactions financières ou des données de sécurité.\\n5. La traduction automatique: Machine Learning est utilisé pour traduire automatiquement des textes en plusieurs langues en utilisant des modèles de machine à apprendre.\\n6. La reconnaissance de parole: Machine Learning est utilisé pour reconnaître la parole dans des enregistrements audio en utilisant des modèles de machine à apprendre.\\n7. Le jeu et la simulation: Machine Learning est utilisé pour créer des jeux et des simulations intelligents qui peuvent apprendre et réagir à l'environnement.\\n8. L'automatisation de processus industriels: Machine Learning est utilisé pour automatiser des processus industriels complexes tels que l'inspection de produits, la qualité des produits et la maintenance prédictive.\\n9. La santé et la médecine: Machine Learning est utilisé pour analyser des données médicales pour diagnostiquer des maladies, prévoir leur progression et suggérer des traitements.\\n10. Le marketing et la publicité: Machine Learning est utilisé pour analyser des données de marketing et de publicité pour personnaliser les contenus et les offres de manière ciblée.\", 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 11, 'total_tokens': 1635, 'completion_tokens': 1624}}\n",
      "{'id': 'cmpl-8cbd868f3c8546e7a9beb76a8a0b03e1', 'object': 'text_completion', 'created': 429254, 'model': 'mistralai/Mistral-7B-Instruct-v0.2', 'choices': [{'index': 0, 'text': \" et donner un exemple pratique\\n\\nLe concept de récursivité est une technique de programmation permettant à une fonction de s'appeler elle-même. Cette technique est utile lorsque la logique d'une fonction peut être décrite en termes récursifs, c'est-à-dire en termes de cas successifs ou de sous-problèmes similaires à celui que la fonction a pour but de résoudre.\\n\\nPar exemple, pensons à la fonction de calcul de la factorielle d'un nombre entier n. La factorielle d'un nombre entier n est le produit de tous les nombres entiers allant de 1 à n. Nous pouvons définir cette fonction de manière récursive en deux étapes :\\n\\n1. Base de récursion : Pour n égal à 0 ou 1, la fonction retourne simplement 1. En effet, la factorielle de 0 ou 1 est définie comme étant 1.\\n2. Cas récursif : Pour n supérieur à 1, la fonction calcule la factorielle de n-1 en appelant la fonction elle-même avec n-1 en paramètre, et retourne le résultat multiplié par n.\\n\\nVoici l'exemple en code Python :\\n\\n```python\\ndef factorielle(n):\\n    if n == 0 or n == 1:\\n        return 1\\n    else:\\n        return n * factorielle(n-1)\\n```\\n\\nCette fonction fonctionne bien pour tous les nombres entiers positifs, mais si on essaye de l'appeler avec un nombre négatif ou un nombre non entier, Python rencontrera une erreur. Pour gérer ces cas d'utilisation, il est important d'ajouter des conditions d'arrêt supplémentaires à notre fonction de manière à l'empêcher de s'enrouler dans une boucle infinie.\\n\\nLes fonctions récursives peuvent également être utilisées pour résoudre d'autres types de problèmes, tels que les calculs itératifs, les algèbres linéaire, les arbres binaires, les graphes, etc. L'avantage de cette technique est qu'elle permet de simplifier la stratégie de programmation en réduisant les problèmes complexes en sous-problèmes plus simples, ce qui peut conduire à des solutions plus courtes et plus lisibles.\", 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 10, 'total_tokens': 581, 'completion_tokens': 571}}\n"
     ]
    }
   ],
   "source": [
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\" Je vais vous présenter une entreprise créée par trois français, un ancien chercheur de DeepMind et deux qui étaient chez Meta.\\n  Cette entreprise, qui n'existait pas il y a à peine huit mois, a eu le temps dans cet intervalle de faire trembler toute l'industrie de l'IA\\n  en publiant des modèles alternatifs à ChatGPT qui explosent toute la concurrence, être valorisé à presque 2 milliards de dollars.\\n  Le tout sans aucune communication, ni vidéo promotionnelle déceptive.\\n  Rien.\\n  Ce que fait cette boîte me hype tellement que je vais quasiment tous les jours sur Twitter exclusivement pour vérifier qu'ils n'ont pas fait des nouvelles annonces.\\n  Et c'est véridique.\\n  C'est vrai ?\\n  Oui.\\n  Laissez-moi vous expliquer à quel point nos petits français ont explosé le game et comment vous pourriez aussi en profiter.\\n  Pour commencer, ce que je vous propose, c'est de regarder un tableau des meilleures intelligences artificielles qui sont concurrentes à ChatGPT.\\n  Vous allez voir, il y a plein de trucs très intéressants dans ce tableau.\\n  Par exemple, on dirait que ChatGPT régresse entre plusieurs versions.\\n  Sinon, on peut voir qu'il y a aussi des scores qui sont incohérents, qui ne sont pas dans le bon ordre, c'est bizarre.\\n  Et surtout, il y a ces petites lignes jaunes.\\n  Open Hermès Mistral, Machin.\\n  Mixtral Instruct.\\n  Que des noms qui évoquent le vent finalement.\\n  Elles ne payent pas de mine.\\n  On dirait même comme ça qu'elles ne sont pas si bien classées.\\n  Mais...\\n  Ce serait passé à côté de la révolution.\\n  Et je pèse mes mots qui se cachent derrière.\\n  Déjà, il faut réaliser qu'il y a pas mal de manières de mesurer la performance d'un LLM.\\n  Mais pour faire court, c'est pas simple.\\n  Vraiment pas simple.\\n  Il y a des benchmarks qui sont en gros des listes de questions qu'on peut poser à un LLM pour vérifier ses capacités.\\n  Donc là, par exemple, petite question de philosophie.\\n  Il faut remplacer avec le bon terme.\\n  Le problème, c'est que c'est déjà arrivé que\\n  des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n\",\n",
       "  \" Ce que fait cette boîte me hype tellement que je vais quasiment tous les jours sur Twitter exclusivement pour vérifier qu'ils n'ont pas fait des nouvelles annonces.\\n  Et c'est véridique.\\n  C'est vrai ?\\n  Oui.\\n  Laissez-moi vous expliquer à quel point nos petits français ont explosé le game et comment vous pourriez aussi en profiter.\\n  Pour commencer, ce que je vous propose, c'est de regarder un tableau des meilleures intelligences artificielles qui sont concurrentes à ChatGPT.\\n  Vous allez voir, il y a plein de trucs très intéressants dans ce tableau.\\n  Par exemple, on dirait que ChatGPT régresse entre plusieurs versions.\\n  Sinon, on peut voir qu'il y a aussi des scores qui sont incohérents, qui ne sont pas dans le bon ordre, c'est bizarre.\\n  Et surtout, il y a ces petites lignes jaunes.\\n  Open Hermès Mistral, Machin.\\n  Mixtral Instruct.\\n  Que des noms qui évoquent le vent finalement.\\n  Elles ne payent pas de mine.\\n  On dirait même comme ça qu'elles ne sont pas si bien classées.\\n  Mais...\\n  Ce serait passé à côté de la révolution.\\n  Et je pèse mes mots qui se cachent derrière.\\n  Déjà, il faut réaliser qu'il y a pas mal de manières de mesurer la performance d'un LLM.\\n  Mais pour faire court, c'est pas simple.\\n  Vraiment pas simple.\\n  Il y a des benchmarks qui sont en gros des listes de questions qu'on peut poser à un LLM pour vérifier ses capacités.\\n  Donc là, par exemple, petite question de philosophie.\\n  Il faut remplacer avec le bon terme.\\n  Le problème, c'est que c'est déjà arrivé que\\n  des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n\",\n",
       "  \" Pour commencer, ce que je vous propose, c'est de regarder un tableau des meilleures intelligences artificielles qui sont concurrentes à ChatGPT.\\n  Vous allez voir, il y a plein de trucs très intéressants dans ce tableau.\\n  Par exemple, on dirait que ChatGPT régresse entre plusieurs versions.\\n  Sinon, on peut voir qu'il y a aussi des scores qui sont incohérents, qui ne sont pas dans le bon ordre, c'est bizarre.\\n  Et surtout, il y a ces petites lignes jaunes.\\n  Open Hermès Mistral, Machin.\\n  Mixtral Instruct.\\n  Que des noms qui évoquent le vent finalement.\\n  Elles ne payent pas de mine.\\n  On dirait même comme ça qu'elles ne sont pas si bien classées.\\n  Mais...\\n  Ce serait passé à côté de la révolution.\\n  Et je pèse mes mots qui se cachent derrière.\\n  Déjà, il faut réaliser qu'il y a pas mal de manières de mesurer la performance d'un LLM.\\n  Mais pour faire court, c'est pas simple.\\n  Vraiment pas simple.\\n  Il y a des benchmarks qui sont en gros des listes de questions qu'on peut poser à un LLM pour vérifier ses capacités.\\n  Donc là, par exemple, petite question de philosophie.\\n  Il faut remplacer avec le bon terme.\\n  Le problème, c'est que c'est déjà arrivé que\\n  des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n\",\n",
       "  \" Open Hermès Mistral, Machin.\\n  Mixtral Instruct.\\n  Que des noms qui évoquent le vent finalement.\\n  Elles ne payent pas de mine.\\n  On dirait même comme ça qu'elles ne sont pas si bien classées.\\n  Mais...\\n  Ce serait passé à côté de la révolution.\\n  Et je pèse mes mots qui se cachent derrière.\\n  Déjà, il faut réaliser qu'il y a pas mal de manières de mesurer la performance d'un LLM.\\n  Mais pour faire court, c'est pas simple.\\n  Vraiment pas simple.\\n  Il y a des benchmarks qui sont en gros des listes de questions qu'on peut poser à un LLM pour vérifier ses capacités.\\n  Donc là, par exemple, petite question de philosophie.\\n  Il faut remplacer avec le bon terme.\\n  Le problème, c'est que c'est déjà arrivé que\\n  des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n\",\n",
       "  \" Mais...\\n  Ce serait passé à côté de la révolution.\\n  Et je pèse mes mots qui se cachent derrière.\\n  Déjà, il faut réaliser qu'il y a pas mal de manières de mesurer la performance d'un LLM.\\n  Mais pour faire court, c'est pas simple.\\n  Vraiment pas simple.\\n  Il y a des benchmarks qui sont en gros des listes de questions qu'on peut poser à un LLM pour vérifier ses capacités.\\n  Donc là, par exemple, petite question de philosophie.\\n  Il faut remplacer avec le bon terme.\\n  Le problème, c'est que c'est déjà arrivé que\\n  des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n\",\n",
       "  \" Vraiment pas simple.\\n  Il y a des benchmarks qui sont en gros des listes de questions qu'on peut poser à un LLM pour vérifier ses capacités.\\n  Donc là, par exemple, petite question de philosophie.\\n  Il faut remplacer avec le bon terme.\\n  Le problème, c'est que c'est déjà arrivé que\\n  des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n\",\n",
       "  \" des modèles cartonnent en théorie avec des scores de fous, mais en fait,\\n  ne soient pas dingues.\\n  Ça arrive assez régulièrement.\\n  Par exemple, c'est potentiellement le cas des modèles de Google.\\n  Genre Gemini.\\n  On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n\",\n",
       "  \" On dirait qu'en fait, ils ont tout fait pour maximiser leur score de MMLU.\\n  Donc qui est un benchmark très prisé et très regardé.\\n  Sauf que apparemment, quand tu l'utilises, c'est dur d'expliquer pourquoi.\\n  Mais tu sens que c'est quand même moins bon.\\n  Que chat GPT 4 et ça peut parfois s'expliquer parce que l'intero a fuité en gros dans le dataset d'entraînement.\\n  C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n\"],\n",
       " [\" C'est comme si les réponses apparaissaient dans les centaines de gigas de texte que le modèle a appris.\\n  Même si les benchmarks peuvent être intéressants, on n'a pas trouvé mieux actuellement que le feeling des humains pour savoir si un modèle est vraiment bon.\\n  Et un des meilleurs benchmark du coup, c'est l'avis des gens.\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Et surtout, est-ce que tel ou tel modèle est vraiment bon ?\\n  Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n\",\n",
       "  \" Il est bien d'avoir une réponse différente de votre modèle et utiliser vraiment en entreprise ou pas.\\n  Du coup, pour faire des classements, comment on fait ?\\n  Et bien en fait, on peut faire un système de vote.\\n  C'est comme aux échecs, on peut faire un ELO, donc un système de points pour comparer des réponses différentes de modèle.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n\",\n",
       "  \" C'est l'un des classements de ce type les plus connus.\\n  Ce qu'on voit, Arena, ELO, en réalité, ça décrit toutes les batailles qui ont été effectuées sur une audience cible entre différentes classes.\\n  Et en fait, on y revient à ce tableau.\\n  C'est l'un des classements de ce type les plus connus.\\n  C'est l'un des classements de ce type les plus connus.\\n  Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n\",\n",
       "  \" Et là, il faut vous dire qu'on voit vraiment le top du top.\\n  C'est-à-dire que cette liste continue en dessous à l'infini.\\n  Même les petites lignes jaunes, on a l'impression qu'elles sont en bas.\\n  Non, non, non, c'est vraiment le podium du podium des tout meilleurs modèles dispo là au moment où on tourne cette émission\\n  qui ont été testées sur le site en question qui est très populaire.\\n  On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n\",\n",
       "  \" On peut voir que pour l'instant, les tout meilleurs modèles en haut, ils sont tous propriétaires.\\n  Donc, on reconnaît les GPT-4 que tout le monde connaît évidemment.\\n  Ensuite, on peut voir Cloud d'Anthropik.\\n  On n'en a pas beaucoup parlé, mais ça a été monté par d'anciens salariés de OpenAI.\\n  Puis, quelques versions de GPT 3.5 qui, après des mises à jour successives, restent en fait toujours très compétitives actuellement.\\n  Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n\",\n",
       "  \" Et plus bas, on aperçoit Google avec le Gemini Pro, leur nouveau modèle annoncé il y a deux semaines à peine.\\n  Tout ça donc, c'est ce qui est propriétaire.\\n  Ok ?\\n  Après, pour ce qui nous intéresse le plus nous, il y a les modèles ouverts.\\n  Ils sont en général plus petits.\\n  On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n\",\n",
       "  \" On va expliquer ce que ça veut dire juste après.\\n  Ils demandent donc moins de puissance de calcul.\\n  On peut les télécharger gratuitement, les faire tourner en local et les réentraîner,\\n  ce qui est un des trucs les plus intéressants, sur nos propres données pour les rendre vraiment très très très très très forts.\\n  Et alors, jusqu'à il y a quelques semaines, il n'y avait en gros qu'une seule alternative.\\n  Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n\",\n",
       "  \" Et c'est ça le point qui est sérieux.\\n  A Tchad GPT et ses variations, dont on avait déjà parlé, c'est l'YAMA 2.\\n  Plus précisément, des versions améliorées, donc fine-tunées de l'YAMA 2, le modèle de Facebook,\\n  qui finissent d'optimiser au max du max le travail qu'a fait faire dans son modèle dit de fondation.\\n  Mais, il y a deux mois exactement, il y a des petites lignes jaunes qui se sont ajoutées au tableau.\\n  Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n\"],\n",
       " [\" Ça s'est passé comment ?\\n  Mistral, le compte Mistral, qui n'était suivi alors par quasiment personne,\\n  a publié un tweet.\\n  Pour ceux qui ne savent pas ce que c'est, c'est un lien magnet.\\n  Donc c'est tout simplement un torrent qu'on peut télécharger avec, bah voilà, un bit torrent quoi,\\n  comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n\",\n",
       "  \" comme on téléchargerait un film piraté ou alors plein d'autres trucs open source.\\n  Il publie ça. Pas d'explication, rien.\\n  Pas de contexte, pas de vidéo promo, pas de billet de bloc, rien.\\n  Juste ce lien.\\n  Et quand on clique dessus, on découvre un modèle à 7 milliards de paramètres.\\n  Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n\",\n",
       "  \" Et là, il faut qu'on explique un truc très important parce que, je vous l'ai dit,\\n  on peut avoir l'impression que ces lignes jaunes, elles sont en bas du classement.\\n  Mais en fait, ça, c'est si tu ne prends pas en compte la taille des modèles.\\n  C'est comme en boxe, il y a différentes catégories.\\n  C'est-à-dire qu'il y a les poids lourds, il y a les moyens et il y a les poids légers.\\n  Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n\",\n",
       "  \" Et en fait, ce n'est pas du tout la même chose de se battre avec des modèles qui font 200 milliards de paramètres\\n  ou avec des modèles qui font 70 milliards ou 7 milliards.\\n  Ce nombre de milliards décrit en fait la taille des poids.\\n  C'est l'énorme fichier qui contient le réseau neuronal qui permet de faire les inférences,\\n  donc de créer les messages, d'écrire sous vos yeux les tokens.\\n  Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n\",\n",
       "  \" Et donc, plus un modèle est gros, plus il demande de la puissance de calcul,\\n  d'avoir des serveurs gigantesques avec des cartes graphiques de Nvidia qui coûtent 25 000 euros pièce\\n  qu'on cumule pour, à la fin, arriver à héberger des modèles qui vont faire du coup 100 gigas par exemple ou 200 gigas.\\n  Souvent, on ne sait pas exactement en plus quelle est la taille des modèles\\n  propriétaires.\\n  À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n\",\n",
       "  \" À une époque, on pensait que les GPT-3 et compagnie faisaient à peu près 130 milliards de paramètres, si je ne dis pas de bêtises.\\n  GPT-4, c'est sûr que c'est énorme.\\n  Autant dire que héberger sur ça vous-même, sur un de vos appareils, c'est mort.\\n  Dites-vous que c'est juste mort.\\n  C'est pour ça que sont apparus des modèles plus petits.\\n  Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n\",\n",
       "  \" Par exemple, l'YAMA, quand ils ont sorti leurs modèles, ils les ont sortis souvent en trois versions, voire quatre.\\n  Il y a le plus gros.\\n  Il fait 70 milliards de paramètres.\\n  Ça, pour vous donner un ordre d'idée, c'est le plus proche de ce qu'on a qui ressemble à une taille de modèle d'OpenAI ou d'Anthropic.\\n  Et ça, pour le faire tourner, il faut en gros minimum deux cadres graphiques des 4080 Ti.\\n  Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n\",\n",
       "  \" Actuellement, c'était un des moyens d'avoir des modèles quasiment équivalents à un GPT-3.5.\\n  Donc, c'était déjà cool.\\n  Ils ont sorti également des modèles de 30 milliards de paramètres.\\n  De 13 milliards de paramètres.\\n  Et de 7 milliards de paramètres.\\n  Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n\"],\n",
       " [\" Et vous pouvez vous dire à quoi ça sert.\\n  Pourquoi ils ne mettent pas plutôt toute leur énergie, tout leur argent à entraîner un unique modèle qui soit plus fort que tous les autres ?\\n  En gros, ça a un intérêt parce que différents modèles, différentes tailles de modèles, sont utiles pour différents trucs.\\n  Tu peux avoir besoin d'un très gros modèle et donc d'une très bonne compréhension, d'une très grande culture générale pour effectuer certaines actions\\n  en faisant des compromis sur le coût par mot, le coût par token.\\n  Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n\",\n",
       "  \" Et le fait d'avoir des très gros modèles.\\n  Des très grosses infrastructures.\\n  Mais parfois, tu peux avoir des besoins plus restreints que tu es prêt à échanger contre des performances.\\n  Donc, par exemple, si tu veux te faire tourner un modèle sur ton Mac mini qui a 16 gigas de RAM,\\n  tu es très content qu'il y ait des modèles 13 milliards ou 7 milliards.\\n  Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n\",\n",
       "  \" Mais pendant très longtemps, avec un modèle de 7 milliards de paramètres, tu ne faisais quasiment rien.\\n  Pour faire des résumés, ça peut marcher un petit peu.\\n  Ou pour essayer de trouver des synonymes à un mot.\\n  Des choses qui jouent avec le langage, mais à un bas niveau.\\n  C'est un élève de CM2, tu peux dire ça.\\n  Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n\",\n",
       "  \" Mistral.\\n  C'est un modèle de 7 milliards de paramètres.\\n  C'est le plus petit qu'on voit être publié.\\n  Il est dans le top 10.\\n  Sauf qu'en fait, il est complètement dingue.\\n  Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n\",\n",
       "  \" Quand ils l'ont sorti, les gens croyaient à moitié.\\n  On pensait qu'il y avait des bugs quand on voyait les benchmarks.\\n  On s'est dit non, mais ce n'est pas possible.\\n  Ce que je vous expliquais, ils l'ont entraîné sur des benchmarks.\\n  Ça n'a pas de sens.\\n  On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n\",\n",
       "  \" On ne devrait pas pouvoir obtenir ce genre de résultat\\n  avec un modèle qui tient dans un fichier.\\n  Ça n'a pas de sens.\\n  Mais en fait, si.\\n  Leur modèle de 7 milliards, surtout quand il a été fonctionné,\\n  c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n\",\n",
       "  \" c'est un peu les noms, les versions, les open Hermès,\\n  tout ça que vous voyez dans le tableau.\\n  Ce sont des versions améliorées par la communauté\\n  qui ont poussé ce modèle à un niveau où\\n  il explose évidemment tous les 13 milliards,\\n  mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n\",\n",
       "  \" mais également les meilleurs modèles en 70 milliards de paramètres.\\n  C'est-à-dire qu'actuellement, la meilleure déclinaison de Mistral,\\n  en 7 milliards de paramètres, c'est Sterling LM7B Alpha.\\n  Elle explose des GPT 3.5 Turbo,\\n  des PPLX 70 milliards,\\n  donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n\"],\n",
       " [\" donc 70B ça veut dire 70 milliards.\\n  C'est la ligne Sterling qu'il faut regarder.\\n  Exactement.\\n  L'IAMA2 70 milliards.\\n  Je ne sais pas si vous vous rendez compte.\\n  La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n\",\n",
       "  \" La prouesse que c'est.\\n  Et c'est ça qui a expliqué qu'il y a deux mois,\\n  il y a eu une sorte de raz-de-marée\\n  où tout le monde s'est mis à jouer avec ce lien magnète,\\n  à le télécharger, à le fin-tuner, à essayer de l'améliorer\\n  et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n\",\n",
       "  \" et à voir où est-ce qu'on pouvait le pousser au maximum du maximum.\\n  Il y a quand même une petite subtilité à capter,\\n  c'est que ça reste un modèle petit.\\n  Et donc, tu peux avoir des réponses ultra qualitatives,\\n  mais on pense que typiquement au niveau de la quantité d'informations,\\n  d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n\",\n",
       "  \" d'Internet qu'il a pu stocker dans sa mémoire,\\n  on pense qu'il va être peut-être un peu plus limité dans certains cas.\\n  Il peut avoir un risque d'halluciner un peu plus souvent,\\n  d'inventer des trucs qui ne sont pas dans son dataset.\\n  C'est peut-être une toute petite nuance qu'on peut donner\\n  au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n\",\n",
       "  \" au fait d'avoir un modèle de 7 milliards.\\n  Mais à part ça, ça veut dire que ce truc-là,\\n  vous pouvez le faire tourner sur certains iPhones\\n  ou de manière plus réaliste sur votre Mac sans aucun problème.\\n  Ça va tourner à la vitesse de l'éclair,\\n  parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n\",\n",
       "  \" parce que c'est vraiment tout petit,\\n  donc c'est bien plus rapide que vous ne pourriez le lire.\\n  Ça veut dire que des développeurs même d'applications\\n  peuvent maintenant l'intégrer en back-end,\\n  en local complètement, sans avoir la moindre connexion Internet,\\n  avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n\",\n",
       "  \" avoir un quasi GPT 3.5.\\n  Vous avez vu que pour l'instant, je n'ai pas parlé d'une petite ligne.\\n  Il en manque une là.\\n  Ça a à peine 10 jours.\\n  Et c'est une autre forme de révolution.\\n  C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n\",\n",
       "  \" C'est-à-dire qu'ils publient simplement un nouveau magnet.\\n  Et alors là, c'est Noël, tu vois, donc tu ouvres le magnet\\n  et tu regardes ce qu'il y a dedans.\\n  Là, il y a un modèle qui s'appelle Mixtral 7B x 8.\\n  Ce qu'ils ont sorti, c'est un modèle dit de MOE.\\n  Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n\"],\n",
       " [\" Donc ça veut dire Mixture of Experts.\\n  Donc un mélange d'experts.\\n  Ce que tu fais, c'est que tu entraînes différents modèles,\\n  mais qui vont se spécialiser dans des domaines différents.\\n  Pour faire simplifier et schématique,\\n  c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n\",\n",
       "  \" c'est un peu comme si tu entraînais un modèle à être super bon en maths,\\n  un autre à être super bon en code,\\n  un autre à être super bon en littérature et en philosophie.\\n  Dans les faits, c'est quand même beaucoup plus compliqué que ça.\\n  Mais ce que ça permet de faire concrètement,\\n  c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n\",\n",
       "  \" c'est d'entraîner un modèle avec différentes branches.\\n  Et en gros, c'est comme un cerbère à huit têtes,\\n  mais où lors de la génération,\\n  donc pour chaque nouveau token généré,\\n  il y a seulement deux de ces têtes qui sont utilisées.\\n  C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n\",\n",
       "  \" C'est probablement, on est quasiment sûrs,\\n  que OpenAI a utilisé cette architecture sur GPT-4.\\n  Et c'est comme ça qu'ils ont réussi à atteindre ce niveau.\\n  Là où c'est intéressant, c'est que, en gros, pour simplifier,\\n  tu bénéficies de la taille d'un modèle qui fait 8 x 7\\n  sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n\",\n",
       "  \" sans en payer le coût au niveau du hardware.\\n  Donc pour le coût d'un 7 plus 7,\\n  donc pour le coût de 14 milliards de paramètres,\\n  tu bénéficies en quelque sorte de 8 x 7.\\n  En fait, il est juste plus gros en taille,\\n  mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n\",\n",
       "  \" mais il ne nécessite pas plus de puissance de calcul, c'est ça ?\\n  Exactement.\\n  En gros, on peut considérer qu'il est à peu près du niveau de GPT 3.5,\\n  peut-être même un peu au-dessus dans les tests.\\n  Mais ce n'est pas ça le plus fou.\\n  Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n\",\n",
       "  \" Le plus fou, c'est que tu peux le faire tourner littéralement en local\\n  sur un Mac M3 Ultra qui a 64 gigas de RAM.\\n  C'est fou.\\n  C'est la première fois de l'histoire que c'est possible.\\n  Et le deuxième truc de fou, c'est le niveau de performance.\\n  Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n\",\n",
       "  \" Parce que pour l'instant, on a juste parlé de l'intelligence,\\n  mais ce n'est pas la seule chose qui compte.\\n  Il y a la vitesse des tokens aussi qui importe.\\n  La rapidité de réponse.\\n  Exactement. À quel point tu vas vite à répondre.\\n  Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n\"],\n",
       " [\" Et eux, non seulement leur modèle est gigasmart,\\n  mais surtout, il peut répondre à énormément d'utilisateurs en même temps.\\n  Donc en gros, ça veut dire que sur ton Mac qui a 64 gigas de RAM,\\n  tu peux débiter du token comme jamais.\\n  Et pour faire le parallèle plus réaliste,\\n  tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n\",\n",
       "  \" tu es une entreprise et tu veux déployer ta propre version de Mistral.\\n  Et j'ai discuté avec pas mal de boîtes qui sont totalement en train de faire ça actuellement.\\n  C'est en train de prendre Mistral, de les fonctionner sur leur version\\n  et de déployer ça sur leur serveur.\\n  Pour ces entreprises-là, ça va coûter beaucoup, beaucoup moins cher\\n  que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n\",\n",
       "  \" que ça ne coûte à OpenAI de faire la même chose.\\n  Pour faire très, très court.\\n  Je pense que vous réalisez du coup que ma hype n'est pas déplacée.\\n  Surtout que pour l'instant, je vous ai parlé de deux petites révolutions.\\n  Il y en a probablement encore à venir en réalité.\\n  Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n\",\n",
       "  \" Et comment on le sait ?\\n  C'est parce qu'ils ont annoncé récemment leur cloud,\\n  donc leur version hébergée de leur modèle qui s'appelle la plateforme.\\n  J'y ai eu accès et c'est en gros une version de l'API d'OpenAI.\\n  Il y a même une rétrocompatibilité.\\n  C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n\",\n",
       "  \" C'est-à-dire que si tu as développé un service pour OpenAI,\\n  c'est les mêmes endpoints, tout marche pareil.\\n  Tu as juste à changer l'UI.\\n  Tu as juste à changer l'URL et tout va bien.\\n  Et du coup, sur cette plateforme, qu'est-ce qu'on a découvert ?\\n  Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n\",\n",
       "  \" Il y a effectivement les deux modèles qu'ils ont déjà publiés.\\n  Mistral Tiny, je crois.\\n  Mistral Small.\\n  Le Mistral Small, pour eux, c'est la petite ligne jaune tout en haut.\\n  Ok.\\n  Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n\",\n",
       "  \" Mais il y a un troisième modèle, Mistral Medium, qui est en alpha.\\n  Celui-là n'a pas été encore publié.\\n  Ce n'est pas exactement d'ailleurs ce qu'ils vont faire.\\n  Mais ce Mistral Medium,\\n  tu peux déjà essayer les inférences dessus.\\n  Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n\",\n",
       "  \" Donc, il y a accès via une API.\\n  Exactement.\\n  Et en gros, ça promet.\\n  Ça promet d'être encore un sacré morceau.\\n  Il est probablement encore plus gros.\\n  Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n\"],\n",
       " [\" Et au niveau du coût, il est bien plus accessible qu'un GPT-4.\\n  On pense en fait qu'il se situe entre les deux.\\n  C'est-à-dire que ce n'est probablement pas encore exactement l'équivalent d'un GPT-4,\\n  mais que ça va te coûter beaucoup, beaucoup moins cher à l'inférence,\\n  ce qui est leur spécialité.\\n  Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n\",\n",
       "  \" Et rapidement après la découverte de ce Mistral Medium,\\n  il y a pas mal de gens qui ont commencé à faire des trades Twitter\\n  où ils font des comparaisons sur des sujets hyper précis\\n  entre GPT-4 et Mistral Medium.\\n  Parce qu'un truc à préciser, c'est que le GPT-4 qu'on voit tout en haut,\\n  c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n\",\n",
       "  \" c'est les versions de l'API.\\n  Il y a pas mal de gens qui commencent à constater que les versions publiques\\n  de OpenAI, de ChatGPT, deviennent de plus en plus débiles.\\n  Ils essayent des trucs qui marchaient il y a encore six mois, un an.\\n  Leur demander de générer des scripts et des trucs comme ça.\\n  Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n\",\n",
       "  \" Ou à une époque où ça marchait bien.\\n  Ils réessaient aujourd'hui, ça marche beaucoup moins bien.\\n  Ce qui se produit souvent, c'est que pour rendre l'IA safe,\\n  pour éviter qu'elle vienne titiller la sensibilité de quiconque,\\n  Politiquement correcte.\\n  Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n\",\n",
       "  \" Exactement.\\n  On a besoin de les contraindre pour qu'elle réponde\\n  « Je suis une IA, je ne peux pas faire de mal » ou des trucs comme ça.\\n  À chaque fois qu'on contraint un modèle à être safe,\\n  on le rend moins performant.\\n  C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n\",\n",
       "  \" C'est une constante.\\n  C'est-à-dire qu'on l'observe absolument partout.\\n  L'un et l'autre sont un trade-off.\\n  C'est toujours une balance.\\n  Du coup, un exemple frappant que j'ai vu,\\n  c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n\",\n",
       "  \" c'est par exemple un exercice de codage en Python.\\n  La demande qui a été formulée à Mixtral d'un côté et à GPT-4,\\n  c'était écrire un script qui peut rentrer un fichier CSV complet\\n  qui fait un milliard de lignes dans une base de données SQL.\\n  Pas besoin de comprendre vraiment l'énoncé.\\n  Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n\",\n",
       "  \" Dites-vous juste que c'est un problème de programmation non trivial.\\n  En gros, c'est un bon moyen de vérifier si vous avez en face de vous\\n  un élève de 3e ou un PhD.\\n  Parce que la bonne réponse, en fait,\\n  c'est que tu ne peux pas simplement faire une boucle\\n  sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n\"],\n",
       " [\" sur l'ensemble des entrées du CSV\\n  et les rentrées dans une base de données.\\n  Il n'y a aucun système.\\n  Tu n'as pas besoin de contexte supplémentaire\\n  pour savoir que c'est juste impossible.\\n  Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n\",\n",
       "  \" Il te faut une manière d'approcher le problème plus intelligente.\\n  Tu fonctionnes avec des batchs.\\n  Tu fais attention à la gestion de ta mémoire vive, des choses comme ça.\\n  Et il fait la démonstration et montre que d'un côté,\\n  dans l'interface de ChatGPT,\\n  dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n\",\n",
       "  \" dans la version 4,\\n  qu'il est complètement à côté de la plaque,\\n  qu'il bullshite des trucs qui ne servent absolument à rien.\\n  Il passe son temps à te dire\\n  « Non, mais ça, implémente-le toi-même. Commentaire. »\\n  Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n\",\n",
       "  \" Bon, ça, c'est quand même un peu trop compliqué, cette boucle.\\n  Donc, ça demanderait beaucoup plus d'investigation.\\n  Tu vois, pas hyper pertinent.\\n  Tu as besoin de lui reposer des questions en mode\\n  « Non, non, mais vraiment, donne-moi le script complet\\n  qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n\",\n",
       "  \" qui répond à l'énoncé. »\\n  Et là, il finit par y arriver.\\n  Preuve qu'il n'est pas con, juste qu'il est devenu paresseux.\\n  La même demande posée à Mistral Medium.\\n  Et il te pond une réponse, mais...\\n  Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" Oh !\\n  C'est du caviar.\\n  Il n'y a pas un token en trop.\\n  Il ne commence pas à te raconter sa vie, etc.\\n  C'est to the point.\\n  Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" Ça te donne du code qui n'est pas exactement forcément complet,\\n  mais où tu as déjà des briques intéressantes,\\n  à savoir un système de batching.\\n  En gros, il a une profondeur, une compréhension dans l'énoncé.\\n  Et à la fin, il te donne des recommandations pour aller plus loin.\\n  Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" Et là, c'est actionnable.\\n  Tu as des trucs très, très précis qui sont évoqués,\\n  des services, des fonctions dans Python que tu pourrais utiliser, etc.\\n  Et alors, c'est un exemple.\\n  C'est-à-dire que tu peux faire des choses\\n  que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\"],\n",
       " [\" que tu ne veux pas faire.\\n  Ça ne vaut rien.\\n  Ce n'est pas une étude approfondie.\\n  Mais moi, j'ai trouvé ça quand même frappant de se dire,\\n  au moment même où on a l'impression que JPT4 est en train de se prendre\\n  les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" les pieds dans le tapis et de devenir pas ouf,\\n  au même moment, tu vois une courbe comme ça sur la performance\\n  et les capacités de Mistral.\\n  Tout ça pour dire merci, Mistral, d'avoir créé cette boîte.\\n  Merci à eux.\\n  Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" Ils sont juste trop forts.\\n  Suivez-les, s'il vous plaît.\\n  Et franchement, je vais dire, c'est le genre de boîte\\n  qui me rend fier d'être là.\\n  Voilà.\\n  C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" C'est tout simplement fou.\\n  Évidemment, ces nouveautés sont très réjouissantes,\\n  mais j'aimerais amener un petit bémol.\\n  Toutes ces IA sont de plus en plus utilisées\\n  pour les connecter à des plugins,\\n  soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" soit pour se balader sur Internet ou se connecter à vos mails,\\n  vos documents, etc.\\n  Le truc, c'est que beaucoup de gens ne réalisent pas\\n  qu'il y a une vulnérabilité, une faille de sécurité\\n  intrinsèque aux modèles de langage.\\n  C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\",\n",
       "  \" C'est assez flippant et très peu abordé.\\n  Et vous pouvez voir une démonstration pour vous faire un avis\\n  dans cette vidéo.\\n  Sous-titrage Société Radio-Canada\"]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the vectorized database\n",
    "df = pd.read_csv('../rag_db.csv')\n",
    "df.embedding = df.embedding.apply(lambda x: eval(x))\n",
    "\n",
    "def get_file_chunk(filename, df):\n",
    "    chunks = df[df.filename == filename.split('.')[0]].text.tolist()\n",
    "    return chunks\n",
    "\n",
    "def group_chunks_by(chunks, nb):\n",
    "    return [chunks[i:i+nb] for i in range(0, len(chunks), nb)]\n",
    "\n",
    "chunks = get_file_chunk('youtube-2.mp3', df)\n",
    "group_chunks_by(chunks, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name flaubert/flaubert_base_uncased. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from flask import Flask, render_template, redirect, url_for, request\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Prompt\n",
    "PROMPT_INNER = \"\"\"Resume le texte ci-dessus.\"\"\"\n",
    "\n",
    "PROMPT = \"\"\"Tu es un expert pour faire des comptes rendues structuré et formel de vidéo.\n",
    "Précédemment, tu as résumé plusieurs parties d'une même vidéo.\n",
    "Je vais t'envoyer l'ensemble de ces-dits résumés que tu as déjà produit.\n",
    "Tu dois maintenant me produire un seul et unique compte rendu faisant une synthèse de l'ensemble de ces résumés.\n",
    "Le résultat final ne doit pas laisser paraitre qu'il s'agit d'une synthèse de plusieurs résumés. Mais bien d'un seul et unique document.\n",
    "Tu dois trouver un titre au document, puis rédiger différentes parties et sous-parties pour structurer l'information.\n",
    "Le résultat doit être écris en français, et sous le format markdown.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT2 = \"\"\"\n",
    "Pour t'aider, voici quelques instructions supplémentaires :\n",
    "- Structure l'information.\n",
    "- Donne un titre au texte.\n",
    "- Decoupe le texte en 2 ou 3 grandes parties en les numerotant et titre les.\n",
    "- Decoupe les parties en sous partie en les numerorant.\n",
    "- Fait un point pour chaque information.\n",
    "- Fait des phrases avec un sujet, un verbe et un complement et un determinant pour les noms pour chaque point.\n",
    "- Ecrit en francais.\n",
    "- Si tu veux ecrire le texte en anglais, ecrit en francais.\n",
    "- On veut que l'information soit structure.\n",
    "- Ecrit entierement ta reponse en markdown, c'est important.\n",
    "- Tu dois ecrire en markdown. \n",
    "- Ne repete pas les memes informations.\n",
    "\"\"\"\n",
    "\n",
    "# Load the model\n",
    "model = SentenceTransformer('flaubert/flaubert_base_uncased')\n",
    "\n",
    "# Load the vectorized database\n",
    "df = pd.read_csv('../rag_db.csv')\n",
    "df.embedding = df.embedding.apply(lambda x: eval(x))\n",
    "\n",
    "def find_closest_chunk(query, df, model, n=3):\n",
    "    query_embedding = model.encode([query])[0]\n",
    "    similarity = df.embedding.apply(lambda x: cosine_similarity([query_embedding], [x])[0][0])\n",
    "    ids = similarity.sort_values(ascending=False).head(n)\n",
    "    return df.loc[ids.index].text.tolist()\n",
    "\n",
    "def get_file_chunk(filename, df):\n",
    "    chunks = df[df.filename == filename.split('.')[0]].text.tolist()\n",
    "    return chunks\n",
    "\n",
    "def group_chunks_by(chunks, nb):\n",
    "    return [chunks[i:i+nb] for i in range(0, len(chunks), nb)]\n",
    "\n",
    "def make_completion_request(prompt):\n",
    "    url = 'http://localhost:8000/v1/completions'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "def make_several_completion_requests(prompts):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        results = executor.map(make_completion_request, prompts)\n",
    "    results = list(results)\n",
    "    return results\n",
    "\n",
    "def make_summary(filename):\n",
    "    # Retrieve chunks\n",
    "    chunks = group_chunks_by(get_file_chunk(filename, df), 8)\n",
    "    prompts = []\n",
    "    for chunk in chunks:\n",
    "        prompt = ''.join(chunk) + \"\\n\\n\" + PROMPT_INNER + \"\\n\\n\"\n",
    "        prompts.append(prompt)\n",
    "    results = make_several_completion_requests(prompts)\n",
    "    summaries = [result['choices'][0]['text'] for result in results]\n",
    "\n",
    "    result = make_completion_request(PROMPT + \"\\\"\" + ''.join(summaries) + \"\\\"\\n\\n\")\n",
    "    return result['choices'][0]['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Je vais vous parler d'un homme qui s'appelle Elon Musk.\\n  Alors, Elon Musk est un homme américain.\\n  Je ne sais pas si vous saviez ça.\\n  C'est une dépêche qui nous vient de Reuters, publiée il y a 5 heures,\\n  donc ça vient juste de tomber.\\n  Il faut que je donne un petit peu de contexte,\\n  pour que vous compreniez un petit peu de quoi ça parle,\\n  avant quand même de vous rentrer là-dedans.\\n  Je ne sais pas si vous voyez mon écran ou pas.\\n  Tout à fait.\\n  Parfait, formidable.\\n  En gros, pourquoi est-ce qu'un juge aurait annulé la rémunération\\n  de 56 milliards de dollars d'Elon Musk par Tesla ?\\n  Il faut savoir déjà, pour vous donner un petit peu de contexte,\\n  qu'aux États-Unis, mais en France et partout dans le monde,\\n  quand tu as une société publique, tu ne fais pas ce que tu veux.\\n  Ce n'est pas comme une société privée.\\n  Qu'est-ce qu'on appelle une société publique ?\\n  C'est une société qui est cotée en bourse.\\n  Quand tu es coté en bourse, n'importe qui dans le monde,\\n  qui a accès à cette place de bourse,\\n  peut investir.\\n  C'est un impact sur plein de petits épargnants dans le monde.\\n  Ça a un impact aussi sur des fonds d'investissement,\\n  sur des fonds de pension, sur des assurances vie,\\n  qui vont peut-être avoir une petite partie de ta société\\n  dans leur holding, etc.\\n  Comme tu as un impact énorme sur la finance d'un pays\\n  et d'une zone géographique,\\n  on considère que tu ne fais pas ce que tu veux\\n  et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n Il faut que je donne un petit peu de contexte,\\n  pour que vous compreniez un petit peu de quoi ça parle,\\n  avant quand même de vous rentrer là-dedans.\\n  Je ne sais pas si vous voyez mon écran ou pas.\\n  Tout à fait.\\n  Parfait, formidable.\\n  En gros, pourquoi est-ce qu'un juge aurait annulé la rémunération\\n  de 56 milliards de dollars d'Elon Musk par Tesla ?\\n  Il faut savoir déjà, pour vous donner un petit peu de contexte,\\n  qu'aux États-Unis, mais en France et partout dans le monde,\\n  quand tu as une société publique, tu ne fais pas ce que tu veux.\\n  Ce n'est pas comme une société privée.\\n  Qu'est-ce qu'on appelle une société publique ?\\n  C'est une société qui est cotée en bourse.\\n  Quand tu es coté en bourse, n'importe qui dans le monde,\\n  qui a accès à cette place de bourse,\\n  peut investir.\\n  C'est un impact sur plein de petits épargnants dans le monde.\\n  Ça a un impact aussi sur des fonds d'investissement,\\n  sur des fonds de pension, sur des assurances vie,\\n  qui vont peut-être avoir une petite partie de ta société\\n  dans leur holding, etc.\\n  Comme tu as un impact énorme sur la finance d'un pays\\n  et d'une zone géographique,\\n  on considère que tu ne fais pas ce que tu veux\\n  et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n Parfait, formidable.\\n  En gros, pourquoi est-ce qu'un juge aurait annulé la rémunération\\n  de 56 milliards de dollars d'Elon Musk par Tesla ?\\n  Il faut savoir déjà, pour vous donner un petit peu de contexte,\\n  qu'aux États-Unis, mais en France et partout dans le monde,\\n  quand tu as une société publique, tu ne fais pas ce que tu veux.\\n  Ce n'est pas comme une société privée.\\n  Qu'est-ce qu'on appelle une société publique ?\\n  C'est une société qui est cotée en bourse.\\n  Quand tu es coté en bourse, n'importe qui dans le monde,\\n  qui a accès à cette place de bourse,\\n  peut investir.\\n  C'est un impact sur plein de petits épargnants dans le monde.\\n  Ça a un impact aussi sur des fonds d'investissement,\\n  sur des fonds de pension, sur des assurances vie,\\n  qui vont peut-être avoir une petite partie de ta société\\n  dans leur holding, etc.\\n  Comme tu as un impact énorme sur la finance d'un pays\\n  et d'une zone géographique,\\n  on considère que tu ne fais pas ce que tu veux\\n  et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n quand tu as une société publique, tu ne fais pas ce que tu veux.\\n  Ce n'est pas comme une société privée.\\n  Qu'est-ce qu'on appelle une société publique ?\\n  C'est une société qui est cotée en bourse.\\n  Quand tu es coté en bourse, n'importe qui dans le monde,\\n  qui a accès à cette place de bourse,\\n  peut investir.\\n  C'est un impact sur plein de petits épargnants dans le monde.\\n  Ça a un impact aussi sur des fonds d'investissement,\\n  sur des fonds de pension, sur des assurances vie,\\n  qui vont peut-être avoir une petite partie de ta société\\n  dans leur holding, etc.\\n  Comme tu as un impact énorme sur la finance d'un pays\\n  et d'une zone géographique,\\n  on considère que tu ne fais pas ce que tu veux\\n  et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n qui a accès à cette place de bourse,\\n  peut investir.\\n  C'est un impact sur plein de petits épargnants dans le monde.\\n  Ça a un impact aussi sur des fonds d'investissement,\\n  sur des fonds de pension, sur des assurances vie,\\n  qui vont peut-être avoir une petite partie de ta société\\n  dans leur holding, etc.\\n  Comme tu as un impact énorme sur la finance d'un pays\\n  et d'une zone géographique,\\n  on considère que tu ne fais pas ce que tu veux\\n  et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n qui vont peut-être avoir une petite partie de ta société\\n  dans leur holding, etc.\\n  Comme tu as un impact énorme sur la finance d'un pays\\n  et d'une zone géographique,\\n  on considère que tu ne fais pas ce que tu veux\\n  et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n et tu impactes tellement les gens\\n  qu'il peut y avoir un juge qui va contester\\n  une décision que tu as prise dans ta propre boîte.\\n  Parce que tu es une boîte publique,\\n  tu n'es pas une boîte privée.\\n  Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n Important quand même de mettre ça.\\n  Donc, Tesla, qui est enregistré\\n  dans le Delaware,\\n  comme beaucoup d'entreprises américaines,\\n  il y a un juge qui vient d'annuler\\n  le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" le paiement que Elon Musk devait avoir\\n  de 56 milliards en forme d'action Tesla.\\n  Grosso modo, ce qui s'était passé,\\n  c'est que le board de Tesla,\\n  les investisseurs de Tesla,\\n  avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n avaient validé ce pay package de 56 milliards\\n  sous réserve qu'il déglingue des objectifs\\n  qui paraissaient impossibles à l'époque.\\n  C'était il y a un petit moment déjà.\\n  C'est un paiement unique.\\n  C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n C'est ses dividendes.\\n  Voilà, en gros, c'est en mode,\\n  donne 20% d'actions Tesla,\\n  on te les redonne, tu vois, machin,\\n  sous réserve que tu atteignes XXX objectifs.\\n  En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n En gros, c'était ça.\\n  C'est un sacré paquet quand même.\\n  Donc, sacré paquet.\\n  Et ça aurait fait de lui\\n  l'homme le plus riche du monde à nouveau.\\n  Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n Et ça aurait été, je crois,\\n  le plus gros paiement unique\\n  à un entrepreneur ever.\\n  Mais voilà.\\n  Le plus gros virement, c'est pas.\\n  C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n C'est ça, oui.\\n  Mais ça a été annulé,\\n  donc, pardon,\\n  c'est une femme,\\n  Kathleen McCormick.\\n  Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n Kathleen McCormick,\\n  c'est pas n'importe qui.\\n  C'est rigolo,\\n  puisque, en fait,\\n  c'est la juge qui avait aussi forcé\\n  Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n Elon Musk à acheter Twitter.\\n  Donc, j'ai l'impression\\n  qu'à la Court of Chancelry\\n  du Delaware,\\n  il a une meuf dédiée\\n  à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" à lui casser les couilles,\\n  ce qui me fait énormément rire.\\n  Mais du coup,\\n  c'est des juges fédérales, c'est ça ?\\n  C'est des juges.\\n  C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n C'est son tuteur.\\n  Court of Chancelry,\\n  je ne sais pas si c'est du...\\n  Je pense que c'est au niveau de l'État,\\n  puisqu'on dirait une sorte\\n  de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n de chambre de commerce, tu vois.\\n  Donc, ça a l'air d'être ça, oui.\\n  Et donc, la question était,\\n  genre,\\n  la board, selon elle,\\n  la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n la board n'a jamais posé\\n  la question à 55 milliards.\\n  Est-ce que ce plan de rémunération\\n  était nécessaire\\n  pour que Tesla garde Musk\\n  et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n et le pousse à rester\\n  et à achever\\n  les objectifs qu'il avait ?\\n  Effectivement, on peut se dire\\n  est-ce qu'il avait vraiment besoin\\n  de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n de 56 milliards pour obtenir ça ?\\n  Ou est-ce que cet argent\\n  n'aurait pas été mieux utilisé\\n  ailleurs dans le business ?\\n  Mais c'est intéressant comme question,\\n  parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n parce qu'on se dirait,\\n  c'est une boîte privée,\\n  ils font bien ce qu'ils veulent, tu vois.\\n  Mais il y a toutes ces questions\\n  qui se posent\\n  quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n quand tu es une boîte publique\\n  complètement lunaire.\\n  Par rapport à, tu vois,\\n  ça n'arriverait jamais, nous,\\n  dans nos sociétés, à nous,\\n  de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" de petites boîtes.\\n  C'est des questions\\n  totalement lunaires.\\n  Donc voilà, et du coup,\\n  Elon Musk, très énervé,\\n  puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n puisqu'il avait en partie besoin\\n  de cet argent-là\\n  pour continuer à financer X,\\n  qui est en sale état financier.\\n  Tesla également,\\n  qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n qui certes,\\n  est cash flow positif,\\n  c'est-à-dire qu'ils rentrent\\n  beaucoup de cash\\n  à un niveau de stabilité,\\n  mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n mais ils ont encore\\n  énormément de dettes chez Tesla.\\n  Donc leur balance sheet\\n  n'est pas vraiment\\n  à l'équilibre non plus.\\n  Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n Donc financièrement,\\n  c'est un petit peu la merde.\\n  Et on a un Elon Musk\\n  qui gueule sur Twitter\\n  en disant\\n  « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n « N'incorporez jamais\\n  votre société dans le Delaware. »\\n  Donc il est très énervé\\n  et il a fait un sondage Twitter\\n  pour dire aux gens\\n  « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n « Est-ce que je devrais\\n  bouger la société au Texas,\\n  là où on a donc\\n  notre gigafactory,\\n  et se barrer définitivement\\n  du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n du Delaware ? »\\n  Voilà !\\n  C'était un peu complexe, machin.\\n  J'ai essayé de vulgariser\\n  un petit peu.\\n  Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" Qu'est-ce que vous en pensez ?\\n  J'ai essayé de résumer\\n  un petit peu ce qui s'est passé.\\n  On sait pourquoi il est allé\\n  dans le Delaware ?\\n  Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n Ouais, il y a deux raisons.\\n  Alors souvent,\\n  il y a la réponse facile\\n  que les gens vont donner\\n  qui est « C'est un paradis fiscal. »\\n  Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n Ce qui est approximativement vrai,\\n  en vrai de vrai,\\n  pour avoir un peu poncé le sujet.\\n  Oui, dans certains cas,\\n  mais pas forcément.\\n  Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n Notamment si tu as une société\\n  dans le Delaware\\n  et que tu es Américain,\\n  mais que tu n'habites pas\\n  dans le Delaware,\\n  tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n tu n'as pas d'avantage fiscal particulier.\\n  Donc ce n'est pas forcément là.\\n  L'avantage du Delaware,\\n  en dehors du truc paradis fiscal,\\n  ce n'est pas ça.\\n  C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n C'est qu'en fait,\\n  ils ont un des tribunaux\\n  les plus pro-business\\n  de tous les États-Unis.\\n  Et donc, souvent,\\n  tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n tu vas te mettre là-bas\\n  parce que du coup,\\n  tu évites de te prendre\\n  des plaintes toutes les semaines\\n  de gens qui veulent\\n  aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n aller te chercher de l'argent\\n  ou qui veulent te faire chier\\n  ou qui ont des machins.\\n  Ou même des gens\\n  qui, malheureusement pour eux,\\n  ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" ont des vrais problèmes avec toi\\n  mais qui du coup,\\n  vont avoir plus de chances\\n  de se faire débouter au Delaware\\n  parce que le Delaware\\n  est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n est plus pro-business\\n  que d'autres États américains.\\n  C'est aussi un arbitrage légal.\\n  Ce n'est pas seulement\\n  un délire de fiscalité.\\n  Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n Le côté pro-business,\\n  ça l'est juste revenu\\n  dans la gueule finalement.\\n  Pour le coup,\\n  la juge n'a pas été\\n  pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n pro-business du tout.\\n  Ok.\\n  Non, bah écoute, je ne sais pas.\\n  Je me demande si c'est sa notoriété\\n  qui fait qu'il est plus\\n  sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n sur le radar des juges ou pas.\\n  Après, si c'est la loi,\\n  écoute, je ne sais pas trop quoi dire.\\n  Le boug est dans la merde\\n  mais après,\\n  s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n s'il avait des objectifs\\n  à remplir chez Tesla\\n  et que ça n'a pas été fait\\n  et que du coup,\\n  il ne mérite pas ses dividendes\\n  et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n et ses actions,\\n  ça paraît logique après.\\n  Moi, j'ai l'impression\\n  qu'il a du mal à assumer\\n  la responsabilité que c'est\\n  d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n d'avoir une entreprise publique\\n  parce que ce n'est pas seulement\\n  un truc positif.\\n  Oui, ce n'est pas pareil.\\n  Quand tu as une boîte publique,\\n  c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" c'est cool parce que tu as accès\\n  à la bourse,\\n  donc tu as accès à un marché\\n  des capitaux quasiment infini\\n  pour te financer\\n  mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n mais en contrepartie,\\n  tu as une régulation\\n  qui est beaucoup plus énervée\\n  que si tu es une simple\\n  petite boîte privée\\n  comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n comme nous trois,\\n  on a des sociétés.\\n  Pour moi,\\n  il s'est fait daronède encore.\\n  C'est comme Elon Musk\\n  à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n à chaque fois\\n  et puis ouin ouin.\\n  Après, est-ce que s'il bouge\\n  sa société,\\n  est-ce qu'il peut passer outre ça\\n  et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n et trouver ses sous bientôt ?\\n  Non, je ne pense pas.\\n  Il devra attendre un an.\\n  Voilà, c'est ça la question.\\n  Il faut faire re-voter\\n  une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n une motion par le board,\\n  ça va prendre un temps fou\\n  et puis rien que bouger\\n  de la société,\\n  ça ne va pas prendre une semaine.\\n  Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n Il est juste dans le caxe\\n  et puis aller voir\\n  le Patreon de Elon Musk\\n  pour le soutenir,\\n  bien sûr.\\n  Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n Il faut lui donner\\n  un maximum de titres.\\n  Oui, il y a Monsieur Fumier\\n  dans mon chat Twitch\\n  qui dit\\n  une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" une boîte publique égale\\n  qui appartient à l'État\\n  en français,\\n  il faut plutôt parler\\n  de société cotée.\\n  C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n C'est vrai qu'en français,\\n  on dirait une société cotée,\\n  une boîte publique,\\n  on pourrait penser\\n  que c'est une boîte...\\n  Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n Vous avez raison.\\n  Defend ?\\n  Moi, je pense\\n  qu'Elon Musk\\n  commence à se faire\\n  un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n un peu rattraper\\n  par le fait\\n  de vouloir croire\\n  qu'il peut faire\\n  ce qu'il veut\\n  quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n quand il veut,\\n  etc.,\\n  que c'est le boss\\n  et qu'il se permet\\n  de cracher sur qui il veut,\\n  etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n etc.\\n  Pendant longtemps,\\n  on a vu Elon Musk\\n  un peu comme le néo Tony Stark,\\n  comme le Tony Stark IRL,\\n  en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n en mode\\n  je casse les codes,\\n  j'y vais,\\n  j'avance, etc.\\n  Ça lui a réussi\\n  dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n dans tout un tas de choses\\n  comme par exemple,\\n  notamment pour moi,\\n  son plus gros succès,\\n  c'est SpaceX,\\n  très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" très honnêtement.\\n  En tout cas,\\n  les ingénieurs de SpaceX,\\n  très honnêtement.\\n  Mais là,\\n  il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n il est en train\\n  de se faire rattraper\\n  par tous ces\\n  gamelles,\\n  toutes ces casseroles\\n  qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n qui traînent.\\n  Je suis un peu dubitatif\\n  parce que d'un côté,\\n  ça durcit l'image\\n  du personnage un peu rebelle\\n  qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n qui,\\n  waouh,\\n  je vais tellement vite,\\n  je veux tellement faire\\n  des trucs américains,\\n  waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n waouh,\\n  même les juges me bloquent\\n  et tout,\\n  vous vous rendez compte ?\\n  Et en même temps,\\n  on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n on se dit,\\n  il commence un peu\\n  à se casser la gueule,\\n  mais je ne sais pas,\\n  moi,\\n  je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n je suis un peu mitigé\\n  sur Elon Musk parfois.\\n  En fait,\\n  j'ai vraiment un avis\\n  sur Elon Musk\\n  très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n très montagne russe.\\n  Parfois,\\n  je trouve ça trop stylé.\\n  Genre par exemple,\\n  quand il rachète X\\n  et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" et il se dit,\\n  vas-y,\\n  on va faire ça,\\n  tout le monde est là\\n  en mode,\\n  ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n ah,\\n  je quitte X,\\n  ah,\\n  X,\\n  ça va fermer,\\n  etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n etc.\\n  Alors que non.\\n  Et en même temps,\\n  quand il y a des news comme ça,\\n  je suis là en mode,\\n  t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n t'es teubé,\\n  mon frère.\\n  Alors moi,\\n  si je peux me permettre\\n  de faire un call,\\n  je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n je pense que ce qu'il est\\n  en train de préparer,\\n  personnellement,\\n  et la suite logique pour lui,\\n  parce qu'en fait,\\n  il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n il a trop de casseroles au cul\\n  légales qui vont le rattraper\\n  et financières,\\n  parce que ses boîtes sont,\\n  en vrai,\\n  très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n très endettées.\\n  Je pense que le truc\\n  qui va le sauver,\\n  s'il y arrive,\\n  c'est qu'il va être\\n  le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n le prochain candidat républicain\\n  à la présidence\\n  après Trump.\\n  Après 2027,\\n  il va essayer de,\\n  je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" je suis certain qu'il va faire ça.\\n  Il y a les épaules pour ça,\\n  tu penses ?\\n  Non.\\n  Moi,\\n  je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n je trouve que ce type\\n  est un abruti,\\n  mais je pense qu'il va essayer\\n  de faire ça.\\n  C'est le mot,\\n  parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n parce qu'il est vachement\\n  conservateur,\\n  en mode très...\\n  Il est allé à fond là-dedans\\n  ces dernières années.\\n  Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n Alors,\\n  on me dit,\\n  il peut pas,\\n  il est pas américain.\\n  C'est vrai qu'il est pas né\\n  sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n sur le sol américain.\\n  Mais il peut tenter un truc\\n  genre vice-président,\\n  il peut tenter d'être\\n  congressman de je sais pas quoi,\\n  il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n il peut tenter un coup comme ça.\\n  Si c'est pas président,\\n  c'est un autre.\\n  Ouais, ouais.\\n  En plus,\\n  c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n c'est vrai qu'en ce moment,\\n  il s'exprime quand même vachement\\n  sur la politique américaine.\\n  Ça, c'est vrai.\\n  Et ça,\\n  ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n ça me fait rire un peu\\n  parce qu'on considère\\n  que dans la tech,\\n  c'est souvent la tech,\\n  un truc de gauchiste,\\n  un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" un truc d'un...\\n  Tu vois,\\n  un truc en mode,\\n  ouais,\\n  tout le monde est là\\n  pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n pour vivre ensemble,\\n  on se kiffe,\\n  tout le monde est bien et tout.\\n  Elon Musk, les frérots,\\n  c'est un droitard de ouf.\\n  J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n J'ai une info,\\n  apparemment,\\n  Trump est né à Pretoria,\\n  donc il était pas américain\\n  non plus à la base.\\n  Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n Non,\\n  alors ça,\\n  je lui parlais d'Elon Musk.\\n  Non, alors Trump,\\n  j'en ai aucune idée.\\n  Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n Ouais, mais du coup,\\n  ça veut dire qu'il y a toujours\\n  moyen,\\n  de toute façon,\\n  de détourner,\\n  de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n de devenir...\\n  Il doit y avoir des détails.\\n  En vrai, mec,\\n  c'est les Etats-Unis,\\n  je suis sûr qu'il doit y avoir\\n  un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n un petit truc\\n  qui lui permettrait.\\n  Mais moi,\\n  ce qui me trigger,\\n  c'est que comment est-ce qu'il fait,\\n  genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n genre,\\n  c'est une vraie question,\\n  comment est-ce qu'il fait\\n  pour continuer à faire avancer\\n  toutes ces boîtes\\n  avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" avec autant de thunes\\n  qui lui manquent,\\n  genre ?\\n  À chaque fois,\\n  quand on entend une news d'Elon Musk,\\n  c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n c'est il a perdu 10 milliards,\\n  il a perdu 40 milliards,\\n  il a perdu 50 milliards.\\n  Genre,\\n  en fait,\\n  pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n pour moi,\\n  c'est deux choses.\\n  C'est déjà,\\n  il a de la marge,\\n  faut pas déconner,\\n  il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n il a quand même un peu de marge,\\n  même si de moins en moins.\\n  Et de deux,\\n  le système financier\\n  est beaucoup basé sur la confiance.\\n  Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n Et non,\\n  on se rend pas compte.\\n  Encore,\\n  on a l'habitude aujourd'hui\\n  que tout est informatisé\\n  dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n dans les banques,\\n  dans machin.\\n  Si toi,\\n  aujourd'hui,\\n  tu veux faire un prêt immobilier,\\n  faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n faut que tu rentres dans les clous,\\n  dans les cases,\\n  c'est un algo qui gère et tout,\\n  machin.\\n  Dans les plus hautes sphères,\\n  dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n dans des investissements VC,\\n  dans des trucs comme ça,\\n  c'est beaucoup de Jacques\\n  qui parle à Paul\\n  parce que Séverine,\\n  elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" elle fait une levée.\\n  Et comme Séverine\\n  a la confiance de Jacques,\\n  alors Paul fait confiance à Jacques.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n Il y a beaucoup,\\n  beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Il y a beaucoup de ça.\\n  Mais non,\\n  mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n mais tu vois,\\n  c'est vraiment comme ça\\n  que ça marche, tu vois.\\n  Et c'est comme ça\\n  que tu lèves des 500 000 balles,\\n  des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n des 1 million,\\n  des 10 millions,\\n  des 50 millions.\\n  C'est beaucoup sur la confiance.\\n  Alors,\\n  il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n il y a quand même une due diligence,\\n  il ne faut pas déconner,\\n  ce n'est pas n'importe quoi,\\n  mais il y a beaucoup\\n  de relationnel et de confiance.\\n  En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n En vrai,\\n  tu peux durer longtemps comme ça.\\n  Il y a un frère de mon chat\\n  qui dit,\\n  Meuse ne paie rien,\\n  c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n c'est ses actions\\n  qu'il voit,\\n  les valeurs baissées et tout.\\n  Mais là,\\n  on parle des dividendes.\\n  Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n Là,\\n  c'est 56 milliards de dividendes,\\n  c'est sa thune en fait.\\n  c'est 55 milliards d'actions.\\n  Ah,\\n  ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" ce n'est pas des dividendes.\\n  Bah oui,\\n  parce que comment est-ce qu'il fait\\n  Elon Musk pour faire de l'argent ?\\n  Il fait comme tout le monde,\\n  il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n il prend ses actions,\\n  il va voir la banque,\\n  il dit bonjour,\\n  j'ai 50 milliards d'actions,\\n  je vous les dépose\\n  et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n et j'aimerais faire un emprunt\\n  de 100 millions.\\n  Et tu fais un emprunt\\n  sur ce que tu as.\\n  En fait,\\n  ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n ils font rouler de la dette\\n  à la base de leurs actions,\\n  c'est un bordel,\\n  mais c'est un peu\\n  la stratégie de base.\\n  La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n La question,\\n  c'est comment tu fais\\n  Attends,\\n  ce n'était pas lui\\n  qui tournait ?\\n  Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. Attends,\\n  Elon Musk,\\n  drug use.\\n  Il y a eu cette news\\n  il y a deux semaines,\\n  comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. comme quoi ses collègues\\n  avaient dit qu'il était\\n  trop drogué en ce moment.\\n  Oui,\\n  c'est ça,\\n  il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. il tourne à la kétamine\\n  Elon Musk,\\n  donc on fait comme on peut.\\n  Ceci explique cela.\\n  Ceci explique cela.\\n  Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk.\\n\\nResume le texte ci-dessus.\\n\\n\",\n",
       " \" Bon,\\n  on verra,\\n  mais juste en add-on\\n  parce qu'il reste deux minutes\\n  avec Elon Musk,\\n  je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. je crois que vous avez vu\\n  le truc Neuralink aussi,\\n  ils ont mis un implant\\n  à un humain\\n  et ils ont dit\\n  que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. que ça se passe\\n  à un humain\\n  très,\\n  très bien.\\n  Donc,\\n  j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. j'ai hâte de voir\\n  comment ça va continuer\\n  à se passer\\n  et le cerveau de la personne\\n  s'est connecté\\n  à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. à un ordinateur.\\n  Voilà,\\n  on se retrouvera bientôt\\n  pour de nouvelles aventures\\n  sur cette news,\\n  bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk. bien sûr.\\n  En tout cas,\\n  j'ai hâte d'être dans trois ans\\n  pour voir la série Netflix\\n  sur Elon Musk.\\n\\nResume le texte ci-dessus.\\n\\n\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'youtube-5.mp3'\n",
    "\n",
    "chunks = group_chunks_by(get_file_chunk(filename, df), 8)\n",
    "prompts = []\n",
    "for chunk in chunks:\n",
    "    prompt = ''.join(chunk) + \"\\n\\n\" + PROMPT_INNER + \"\\n\\n\"\n",
    "    prompts.append(prompt)\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Elon Musk, l'homme d'affaires américain, devait recevoir 56 milliards de dollars en forme d'actions Tesla en récompense d'un paquet de rémunération validé par le board et les actionnaires de la société, en vertu d'un accord qui comprenait la réalisation de certains objectifs impossibles à l'époque. Cependant, un juge de la Cour de Chancellerie du Delaware a récemment annulé ce paiement, car Tesla étant une société publique cotée en bourse, les décisions qu'elle prend peuvent avoir un impact considérable sur les épargnants, les fonds d'investissement, les fonds de pension et les assurances-vie. En tant que société publique, Tesla ne peut pas agir à sa guise et peut être contrainte à faire des décisions qui impactent beaucoup de gens. La juge Kathleen McCormick a annulé le paiement, ce qui met un terme au projet de Musk de devenir à nouveau le plus riche homme du monde, ce qui aurait été le paiement unique le plus élevé à un entrepreneur. La juge McCormick a déjà forcé Musk à acheter Twitter, ce qui laisse penser qu'elle a une certaine détermination pour contrôler les décisions des entreprises du Delaware.\",\n",
       " 'Le texte discute de l\\'annulation du paquet de rémunération de 56 milliards de dollars qui était prévu pour Elon Musk, le PDG de Tesla. Ce paquet de rémunération était conditionnel à l\\'atteinte de certains objectifs par Musk. Toutefois, ce paquet a été annulé par une juge de la Cour de Chancelry du Delaware, Kathleen McCormick, qui a été décrite comme une \"femme dédiée à casser les couilles\" de Musk. La question se pose de savoir si ce paquet de rémunération était nécessaire pour que Tesla garde Musk et le pousse à rester et à atteindre ses objectifs, ou si cet argent aurait été mieux utilisé ailleurs dans l\\'entreprise. Cela fait référence à l\\'achat de Twitter par Musk, qui a été forcé par la Cour de Chancelry du Delaware. La question est posée si Tesla, comme une entreprise publique complètement dérangée, aurait jamais permis à Musk d\\'acheter Twitter, et si les questions qui s\\'y posent ne seraient pas totalement lunaires pour une petite entreprise. Musk a réagi très en colère à l\\'annulation de ce paquet de rémunération.',\n",
       " \"Elon Musk, le PDG de Tesla, a été lui-même incité à démissionner de son poste en raison d'un plan de rémunération controversé de 56 milliards de dollars. La Cour de Chancellerie du Delaware, qui supervise les affaires des sociétés détenues par l'État, a examiné si ce plan était nécessaire pour garder Musk et pousser Tesla à atteindre ses objectifs. Les juges ont conclu que la question de 55 milliards n'avait jamais été posée et que Musk aurait pu utiliser cet argent de manière plus efficace ailleurs dans l'entreprise. Musk, qui avait un besoin partiel en argent pour continuer à financer SpaceX, qui était en mauvais état financier, et Tesla, qui avait une balance sheet imparfaite malgré son statut de rentabilité, ont été mis en évidence financièrement instables. Musk a réagi en lançant un sondage Twitter pour demander aux gens s'ils pensaient qu'il devrait déplacer la société de Tesla au Texas, où se trouve son usine gigafactory, et se séparer définitivement du Delaware.\",\n",
       " \"Elon Musk a annoncé sur Twitter qu'il envisageait de quitter le Delaware pour implanter sa société à Texas en raison d'un sondage qu'il avait lancé. Le Delaware est connu pour être un paradis fiscal, mais Musk a également indiqué qu'il y a d'autres raisons pour choisir ce État. En réalité, le Delaware est réputé pour son tribunal pro-business qui permet aux sociétés de se protéger contre certaines poursuites et de gagner du temps en matière de procédures judiciaires. Musk semblait être frustrationné par le coût financier de la société Tesla, qui est en train de perdre de l'argent et a de lourdes dettes. Il a également mentionné Tesla X, qui est également en mauvaise situation financière. Musk a demandé au public s'il pensait qu'il devrait abandonner le Delaware pour le Texas.\",\n",
       " \"The text discusses why Elon Musk registered Tesla, Inc. in Delaware instead of in California, where the company is based. The primary reasons are Delaware's pro-business legal system, which provides a more favorable business environment and can help companies avoid frequent lawsuits. Additionally, Delaware offers favorable corporate tax laws, making it an attractive jurisdiction for corporations. However, these advantages do not apply equally to all companies, and the decision to register in Delaware ultimately depends on a company's specific circumstances. The text also touches upon the idea that Musk's notoriety may have played a role in the decision.\",\n",
       " \"Elon Musk, qui a rencontré des difficultés juridiques en raison de son rôle de PDG de Tesla, une société cotée, est comparé à un bouc émissaire parce que la régulation des entreprises publiques est plus rigoureuse que celle des entreprises privées. La juge a rejeté une motion de Musk pour réduire l'impôt sur les dividendes à un taux plus faible, ce qui a affecté l'évaluation des actions de Tesla. Musk a du mal à assumer la responsabilité d'avoir une entreprise publique, car ce n'est pas seulement un avantage, mais il implique une régulation plus énervée. Selon les experts, les investisseurs peuvent attendre un an avant que Musk puisse trouver de nouveaux investisseurs pour Tesla, car il doit faire réviser par le conseil d'administration une motion pour bouger la société. Musk a fait référence à Elon Musk, qui est souvent dans la merde et demande des fonds sur Patreon, et a proposé de donner à Musk un maximum de titres en tant qu'investisseur potentiel. Monsieur Fumier dans le chat Twitch a souligné que les sociétés cotées n'appartiennent pas à l'État, mais plutôt à des actionnaires.\",\n",
       " \"Le texte parle de la situation de Elon Musk et de sa société SpaceX. Il explique que Musk a été habité par le succès et a eu l'impression de pouvoir faire ce qu'il veut, cracher sur qui il veut, sans prendre en compte les conséquences. Toutefois, il est maintenant confronté à la réalité d'être une société cotée, qui implique une régulation plus forte que pour une petite entreprise privée. Il mentionne que Musk a dû attendre un an avant de pouvoir bouger sa société, et qu'il devra faire ré voter une motion par le board pour qu'elle puisse bouger. Le texte souligne que Musk a été comparé à Tony Stark, le personnage de fiction de Marvel, et que ses succès, notamment celui de SpaceX, sont impressionnants. Toutefois, il a commencé à être rattrapé par la réalité et la complexité de gérer une société cotée.\",\n",
       " \"Le texte ci-dessus parle de Elon Musk et de sa perception publique. Il a longtemps été vu comme un entrepreneur rebelle et innovant, comparable au personnage de Tony Stark du Marvel Universe. Cependant, il commence à être critiqué et rattrapé par certaines controverses et actions controversées. Le texte critique la façon dont Musk croit pouvoir faire ce qu'il veut, malgré les obstacles juridiques, et son attitude arrogante envers les gens. Le texte est dubitatif sur l'image de Musk, mettant en évidence ses succès, notamment avec SpaceX, tout en notant que ses méthodes et son attitude peuvent durcir l'image du personnage. Le texte finit en disant que Musk est très montagne russe et que certains de ses actions peuvent être trop stylées.\",\n",
       " \"Le texte discute de l'entrepreneur Elon Musk et ses actions, telles que l'achat de Tesla et sa relation avec les tribunaux. L'auteur est d'abord fasciné par Musk et sa volonté de faire des choses rapidement et innovatives, mais il se rend compte que Musk est pris dans des affaires juridiques et financières qui le ralentissent. L'auteur est un peu douteux sur Musk et trouve quelque chose trop stylé dans ses actions. Il suggère que Musk pourrait être le prochain candidat républicain à la présidence après Trump, mais c'est une simple hypothèse.\",\n",
       " 'Le texte décrit une conversation entre deux personnes sur un sujet controversé impliquant une personne dite \"X\". Les deux personnes se livrent des commentaires sur X et ses possibles intentions politiques, notant qu\\'il est non-américain mais pourrait tenter une carrière politique américaine. Elles expriment leurs opinions sur X, caractérisant-le comme un abruti et un conservateur, en dépit de ses dettes et difficultés financières. Elles discutent aussi du fait que X s\\'exprime régulièrement sur la politique américaine et qu\\'il pourrait être le prochain candidat républicain à la présidence après Trump. Les deux personnes s\\'amusingent un peu à l\\'idée que dans le monde de la tech, les personnes politiquement gauchistes sont plus courantes. Le texte contient des langues vulgaire et des commentaires disrepectueux envers X.',\n",
       " \"Le texte discute de la possibilité de Elon Musk devenant le président des États-Unis, malgré le fait qu'il n'est pas né sur le sol américain. Les interlocuteurs s'amusent de l'idée, mais mentionnent qu'il peut essayer de trouver une autre façon d'être impliqué en politique américaine, comme devenir vice-président ou un membre du Congrès. Le sujet de discussion passe ensuite sur Donald Trump, qui est mentionné avoir été né à Pretoria, en Afrique du Sud, ce qui signifie qu'il n'était pas non plus américain à la naissance. Cependant, ils concluent que Trump a fait carrière en politique américaine, alors qu'Elon Musk peut essayer de le faire de la même manière. Ils se moquent de certains aspects de la politique américaine et de certaines personnalités, en utilisant des termes et des expressions informelles.\\n\\n\\n1. Elon Musk could possibly become the President of the United States even though he was not born on American soil.\\n2. He could try to become a vice-president or a congressman instead.\\n3. Donald Trump, who was born in Pretoria, South Africa, also did not start his political career on American soil.\\n4. The speakers make fun of American politics and certain figures using informal language.\",\n",
       " \"Ce texte est une conversation entre deux personnes discutant de l'entrepreneur Elon Musk et du président des Etats-Unis, Donald Trump. Elles se demandent comment ces hommes ont pu continuer à avoir succès financièrement malgré leurs défaites et pertes importantes. Elles soulignent que le système financier repose sur la confiance et que Musk a toujours eu assez de marge pour affronter ses pertes. Elles s'amusent également à imaginer que Trump ait été né à Pretoria, ce qui aurait signifié qu'il n'était pas américain à la naissance et donc pas éligible à la présidence des Etats-Unis. Les deux personnes se disent qu'il doit y avoir des détails sur les façons dont Musk et Trump ont pu continuer à faire avancer leurs entreprises malgré leurs défaites financières. Elles soulignent que le système financier repose sur la confiance, et que les décisions d'investissement sont souvent basées sur la réputation et la confiance de certains investisseurs. Elles notent que les plus hautes sphères financières fonctionnent de manière similaire à un réseau social, avec des personnes qui se connaissent et font confiance les unes aux autres. Elles concluent en disant que Musk a perdu beaucoup d'argent, mais qu'il a toujours eu de la marge pour continuer à faire avancer ses entreprises.\\n\\nKeywords : Elon Musk, Donald Trump, finance, confiance, investissements, marge, système financier.\\n\\nEdit: I corrected some spelling mistakes and formatting issues. I also added some context to the text and provided a summary of its main ideas. Let me know if there's anything else I can help you with.\\n\\nNote: The text contains some informal language and colloquial expressions that might not be suitable for all audiences. It also contains some strong opinions and speculations that might not be based on facts.\",\n",
       " \"Le texte parle de la fortune d'Elon Musk et des pertes qu'il a engendrées dans le secteur financier. Le locuteur explique que malgré les pertes, Musk toujours a de la marge et que le système financier repose sur la confiance. Il mentionne l'habitude moderne de penser que tout est informatisé dans les banques et les investissements, et que les relations et la confiance jouent un grand rôle dans les investissements. Il souligne que même si Musk a perdu beaucoup d'argent, il a encore des dividendes importants issus de ses actions, ce qui constitue sa fortune réelle. Le texte rapporte également que Musk gagne de l'argent de la même manière que tout le monde et qu'il y a toujours une due diligence et une vérification des informations avant de faire des investissements.\",\n",
       " \"Le texte discute de l'acquisition de actions et des dividendes dans le monde des affaires. Il met en évidence le rôle important de la confiance et de la due diligence dans ces transactions. On parle aussi du cas d'Elon Musk et des rumeurs sur son utilisation de drogues. Le texte souligne que la stratégie de base consiste à faire rouler de la dette à la base des actions. Le dernier paragraphe annonce une prochaine interview avec Elon Musk.\",\n",
       " \"Cet article discute de l'entrepreneur Elon Musk et de ses techniques d'affaires controversées. Musk est connu pour prendre des risques financiers et pour faire fréquemment usage de dette pour financer ses entreprises. Il a également été accusé d'utiliser des drogues telles que la kétamine. Le texte discute également de l'entreprise Neuralink, qui a récemment implanté un chip dans le cerveau d'un humain, et de la possibilité qu'il y a des séries Netflix à propos de Musk dans trois ans. Le texte est écrit dans un style humoristique et sarcastique.\",\n",
       " \"Dans ce texte, le locuteur parle de l'évènement Neuralink où un humain a reçu un implant permettant à son cerveau de se connecter à un ordinateur. Il est impatient de voir comment cette technologie évolue et s'attend à une série Netflix sur Elon Musk dans trois ans.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = make_several_completion_requests(prompts)\n",
    "summaries = [result['choices'][0]['text'] for result in results]\n",
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1. Elon Musk's business strategies have been controversial and have involved taking risks and using debt to finance his companies.\\n2. He has also been accused of using drugs such as ketamine.\\n3. A recent event by Neuralink, where a human received a brain implant to connect to a computer, has generated excitement and anticipation for the future of this technology.\\n4. It is speculated that there will be Netflix series about Elon Musk in the future.The text discusses Elon Musk's business strategies, which involve taking risks and using debt to finance his companies. It also mentions his alleged use of drugs like ketamine. The text then talks about Neuralink, a recent event where a human received a brain implant that allowed their brain to connect to a computer. The text expresses excitement and anticipation for the future of this technology and speculates that there will be Netflix series about Elon Musk in the future.\\n\\nKeywords: Elon Musk, business strategies, debt, risks, drugs, Neuralink, Netflix.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = make_completion_request(PROMPT + \"\\\"\" + ''.join(summaries) + \"\\\"\\n\\n\")\n",
    "result['choices'][0]['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Elon Musk's business strategies have been controversial and have involved taking risks and using debt to finance his companies.\n",
      "2. He has also been accused of using drugs such as ketamine.\n",
      "3. A recent event by Neuralink, where a human received a brain implant to connect to a computer, has generated excitement and anticipation for the future of this technology.\n",
      "4. It is speculated that there will be Netflix series about Elon Musk in the future.The text discusses Elon Musk's business strategies, which involve taking risks and using debt to finance his companies. It also mentions his alleged use of drugs like ketamine. The text then talks about Neuralink, a recent event where a human received a brain implant that allowed their brain to connect to a computer. The text expresses excitement and anticipation for the future of this technology and speculates that there will be Netflix series about Elon Musk in the future.\n",
      "\n",
      "Keywords: Elon Musk, business strategies, debt, risks, drugs, Neuralink, Netflix.\n"
     ]
    }
   ],
   "source": [
    "print(result['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
